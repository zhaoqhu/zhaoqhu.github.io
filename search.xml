<?xml version="1.0" encoding="utf-8"?>
<search>
  
    <entry>
      <title><![CDATA[Wuqing]]></title>
      <url>/2025/11/04/wuqing/</url>
      <content type="text"><![CDATA[武清商圈  佛罗伦萨小镇  创意米兰生活广场  V1汽车世界  威尼都  天津武清福源万达广场  住总大光明中心  友谊商厦（武清店）  荔隆时代广场/荔隆广场  瑞安威尼都]]></content>
      <categories>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Hugging face 学习记录]]></title>
      <url>/2025/10/21/huggingface/</url>
      <content type="text"><![CDATA[Hugging face  hugging face入门教程，可以在自己的macbook pro 15款上学习和练习huggging face吗？  我的macbook pro 15款8+256G的有docker环境，第一部分Huggingface的Python环境可以用docker的python环境吗？环境准备安装Python 3.9Pip安装PyTorchPip安装Hugging Face核心库transformer和datasets]]></content>
      <categories>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[mysql面试题]]></title>
      <url>/2025/10/11/mysql-ms/</url>
      <content type="text"><![CDATA[MySQLMysql索引用的是什么算法Mysql选用的是B+树，B+树主要是查询效率高，时间复杂度是O(logmN)，内部节点可以拥有多个子节点，通常大于2，这使得B+树比二叉树更宽，更矮时间复杂度是O(log2N)有助于减少树的高度，进而减少磁盘I/O操作。总结：Mysql中创建索引的目的是为了更快的查询，索引选用B+树的数据结构，这种结构的查找算法的时间复杂度是O(logmN)，查找的效率快，磁盘I/O操作少。MySQL事务的关键特性  原子性事务是操作的最小单元，要么全成功，要么全回滚。原子性是指开启事务后数据库的修改操作要么都成功，要么都失败，回滚到事务之前的状态。  一致性事务执行前后，数据库从一个合法状态变为另一个合法状态（如转账总金额不变）。一致性是指遵守资金守恒原则，例如银行转账操作A账户转出一定的金额给B账户，为了得到一致性这个事务需要确保金额从A减少并在增加。  隔离性多事务并发时互不干扰，默认隔离级别REPEATABLE READ通过MVCC和间隙锁避免脏读、不可重复读、部分幻读隔离性，在并发事务T1和T2都需要更新同一个账户的余额，若没有隔离措施，T1和T2可能会使用同样的金额进行计算，从而导致结果错误。  持久性mysql事务提交后永久保存，宕机不丢失。MySQL事务隔离级别      读未提交    A事务可以读取B事务未调教的数据，引发脏读。        读已提交    A事务可以读取B事务已提交的数据        可重复读    默认的事务隔离级别，事务开启时，不在允许修改操作，可避免脏读。        串行    串行是最高的隔离级别，可以避免脏读、幻读、可重复读，但是性能太差。  MySQL存储引擎  InnoDBInnoDB是默认的存储引擎，支持事务、行锁，支持多版本并发控制。  MyIsAmMyIsAm在5.5版本之前是默认的选项，不支持事务、行锁，支持表锁。适合读密集应用，数据压缩能力强，适合只读数据存储。  Memory将所有数据保存在内存中，数据易丢失。  Archive设计用于存储大量的归档数据，具有高压缩率。只支持Insert和Select操作，非常适合存储日志数据或其他很少需要修改的数据。MySQL高可用方案  主从复制适合读密集型应用  InnoDB Cluster适合大规模并发写入应用。MySQL中utf8和utf8mb4的区别mysql在5.5.3之后增加了utf8mb4的编码，mb4就是most bytes4，utf8编码最大字符长度为3字节，如果遇到4字节的宽字符就会插入异常。utf8mb4就是most bytes4的意思，专门用来兼容4字节的unicode字符。MySQL中乐观锁和悲观锁的区别？传统的关系型数据库里边就用到了很多这种锁机制，比如行锁、表锁等，读锁、写锁等。都是在做操作之前先上锁。乐观锁和悲观锁主要是为了解决并发事务中的数据一致性问题，他们的设计初衷是为了在多用户或进程同时访问和修改相同数据时，保证数据的一致性和完整性。举例：在秒杀场景下对库存的查询加锁，在这个事务结束前，其他并发事务需要阻塞排队等待。MySQL索引主要是哪些？索引的目的是提高查询效率，索引的类型有唯一索引、普通索引、主键索引、组合索引。唯一索引不可以出现相同的值，可以有Null值。索引使用技巧，1.使用短索引，如果有一个char(255)列，可以在前10个或20个字符内做短索引。2.使用like语句%aaa%，不会使用索引，而 “aaa%”可以使用索引。3.where和join的列键索引。组合索引最左匹配原则？在查询数据时，从联合索引的最左边开始匹配。MySQL会一直向右匹配直到遇到范围查询(&gt;、&lt;、betwwen、like就停止匹配了)，比如索引列(abcd) where a=1 and c=2 and b&gt;5 and d=6，这样c和d都不会用到索引。聚簇索引和非聚簇索引的区别？MyIsAM存储引擎是非聚簇索引，InnnoDB是聚簇索引。聚簇索引中主键索引存放数据，二级索引存储索引列和主键列。非聚簇索引主键索引和二级索引都存放完整的数据。聚簇索引会额外占用空间，但查询效率高。如何查询一个字段是否命中了索引？使用explain分析SQL是否走了索引。Mysql中的MVCC是什么？多版本并发控制Multiversion concurrency control，多版本并发控制常用的是所，给当前事务DQL加毒素哦，给DML加写锁，这种锁是一种悲观锁的实现方式，会阻塞其他事务，从而影响数据库性能。MySQL读写分离以及主从同步。原理，主库将变更写binlog日志，然后从库链接到主库后，从库有一个IO线程将主库的binlog日志拷贝到自己本地，写入一个中继日志，接着从库有一个sql线程从中继日志读取binlog然后执行binlog日志的内容。Mysql如何保证一致性和持久性？Mysql为了保证ACID中的一致性和持久性，使用了WAL(Write A head logging)，先写日志在写磁盘。Redolog就是一张WAL的应用，当数据库忽然断点在重新启动时，Mysql可以通过Redolog还原数据。为什么选B+树作为索引结构？1.非叶子节点仅存索引（键值和指针），支持高效范围查询。2.叶子节点存数据并链表连接天然支持水平扩展理论存储容量仅受磁盘总空间限制。3.B+树的节点（非叶子和叶子）大小设计为磁盘页（16KB）大小，让B+树查询时用最少的I/O定位数据。InnnoDB的行锁模式？1.共享锁(s)，用法lock in share mode又称读锁，2. 排它锁，又称写锁。s锁，若事务T对数据对象A加上S锁，其他事务智能对A加S锁，而不能加X锁。x锁，若事务T对数据对象加上X锁，事务T可以读A也可以写A，其他事务不能在对A加任何锁，X锁用法for update。哈希(hash)比树(tree)更快，索引结构为什么设计成树形哈希查询、插入、修改、删除的平均响应时间复杂度都是O(1)，树的平均响应时间复杂度是O(logmN)，哈希只能满足等值查询，不能满足范围和大小查询，其次不可以排序。为什么索引的key长度不能太长。key太长会导致一个页当中能够村昂的key数目变小，间接导致索引树的页数变多，索引层次增加。从而影响查询效率。MySQL的数据如何恢复到任意时间点1.启用二进制日志。2.首先使用最近一次的备份恢复数据库。3.使用mysqlbinlog工具将binlog文件合并，然后使用mysql工具导入已合并的sql文件。Mysql为什么加了索引可以加快查询使用索引后再查询时不用扫描全表来定位。Explain命令有什么用分析慢查询语句有没有命中索引。]]></content>
      <categories>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Go Redis学习笔记]]></title>
      <url>/go/2025/09/23/go-redis-note/</url>
      <content type="text"><![CDATA[安装go get github.com/redis/go-redis/v9使用例子package mainimport (	"context"	"fmt"	"log"	"time"	"github.com/redis/go-redis/v9")func main() {	rdb := redis.NewClient(&amp;redis.Options{		Addr:     "localhost:16379",		Password: "CXqwr12_", // no password set		DB:       0,          // use default DB	})	var ctx = context.Background()	pong, err2 := rdb.Ping(ctx).Result()	if err2 != nil {		//panic(err2)		log.Printf("redis connect failed,err:%v", err2)	}	fmt.Println("redis connect success:", pong)	err := rdb.Set(ctx, "go-redis-key", "redis-go-value", 0).Err()	if err != nil {		//panic(err)		log.Printf("set key failed,err:%v", err)	}	rdb.Set(ctx, "go-redis-key2", "redis-go-value2", 300*time.Second)	rdb.Set(ctx, "go-redis-key3", "redis-go-value3", 60*time.Second)	rdb.Set(ctx, "go-redis-key4", "redis-go-value3", 160*time.Second)	rdb.HSet(ctx, "go-redis-hash-key1", "field1", "hash-value1")	rdb.HSet(ctx, "go-redis-hash-key1", "field2", "hash-value2")	rdb.HSet(ctx, "go-redis-hash-key1", "field3", "hash-value3")	//val, err := rdb.Get(ctx, "go-redis-key").Result()	val, err := rdb.Get(ctx, "key").Result()	if err != nil {		//panic(err)		log.Printf("get key failed,err:%v", err)	}	fmt.Println("key", val)	deleted, err := rdb.Del(ctx, "go-redis-key3", "go-redis-key2").Result()	if err != nil {		log.Printf("delete key failed,err:%v", err)	}	fmt.Print("deleted is ", deleted)	deleted, err = rdb.HDel(ctx, "go-redis-hash-key1", "field1", "field2").Result()	if err != nil {		log.Printf("delete key failed,err:%v", err)	}	fmt.Print("HDel deleted is ", deleted)	//ctx := context.Background()}参考资料  https://github.com/redis/go-redis  https://redis.uptrace.dev/zh/  https://pkg.go.dev/github.com/redis/go-redis/v9@v9.14.0#section-readme]]></content>
      <categories>
        
          <category> Go </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Go Gorm Mysql学习笔记]]></title>
      <url>/go/2025/09/23/go-gorm-mysql-note/</url>
      <content type="text"><![CDATA[安装go get -u gorm.io/gormgo get -u gorm.io/driver/sqlite连接数据库package mainimport (	"context"	"encoding/json"	"fmt"	"gorm.io/driver/mysql"	"gorm.io/gorm")func connectDB(dsn string) (*gorm.DB, error) {	db, err := gorm.Open(mysql.Open(dsn), &amp;gorm.Config{})	return db, err}func main() {	dsn := "root:12345678@tcp(127.0.0.1:13301)/nextcloud?charset=utf8mb4&amp;collation=utf8mb4_bin&amp;parseTime=True&amp;loc=Local"	db, err := connectDB(dsn)}模型gorm.Modelgorm.Model是gorm预定义的结构体，在自定义的结构体模型中可以引入使用。  gorm.Model definition// gorm.Model definitiontype Model struct {  ID        uint           `gorm:"primaryKey"`  CreatedAt time.Time  UpdatedAt time.Time  DeletedAt gorm.DeletedAt `gorm:"index"`}myGormModelTest模型定义和执行package mainimport (	"context"	"encoding/json"	"fmt"	"gorm.io/driver/mysql"	"gorm.io/gorm")type myGormModelTest struct {	gorm.Model}func connectDB(dsn string) (*gorm.DB, error) {	db, err := gorm.Open(mysql.Open(dsn), &amp;gorm.Config{})	return db, err}func main() {	dsn := "root:12345678@tcp(127.0.0.1:13301)/nextcloud?charset=utf8mb4&amp;collation=utf8mb4_bin&amp;parseTime=True&amp;loc=Local"	db, err := connectDB(dsn)	ctx := context.Background()	if err != nil {		fmt.Println("connect db failed,err:", err)		return	}	err = db.Set("gorm:table_options", "ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin").AutoMigrate(myGormModelTest{})	if err != nil {		fmt.Println("migrate failed,err:", err)		return	}}生成数据库表结构是show create table my_gorm_model_testsCREATE TABLE `my_gorm_model_tests` (  `id` bigint unsigned NOT NULL AUTO_INCREMENT,  `created_at` datetime(3) DEFAULT NULL,  `updated_at` datetime(3) DEFAULT NULL,  `deleted_at` datetime(3) DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `idx_my_gorm_model_tests_deleted_at` (`deleted_at`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_binUser模型定义和执行package mainimport (	"context"	"encoding/json"	"fmt"	"gorm.io/driver/mysql"	"gorm.io/gorm")type User struct {	gorm.Model	UserName string `gorm:"column:user_name;size:100;not null;default:'';"`	Age      int    `gorm:"column:user_age"`	Email    string `gorm:"column:user_email"`	Phone    string `gorm:"column:user_phone"`}func (u *User) TableName() string {	return "my_gorm_user"}func connectDB(dsn string) (*gorm.DB, error) {	db, err := gorm.Open(mysql.Open(dsn), &amp;gorm.Config{})	return db, err}func main() {	dsn := "root:12345678@tcp(127.0.0.1:13301)/nextcloud?charset=utf8mb4&amp;collation=utf8mb4_bin&amp;parseTime=True&amp;loc=Local"	db, err := connectDB(dsn)	ctx := context.Background()	if err != nil {		fmt.Println("connect db failed,err:", err)		return	}	// 使用 AutoMigrate 进行迁移	err = db.Set("gorm:table_options", "ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin").AutoMigrate(&amp;User{})	if err != nil {		fmt.Println("migrate failed,err:", err)		return	}}生成数据库表结构是show create table my_gorm_userCREATE TABLE `my_gorm_user` (  `user_name` varchar(100) COLLATE utf8mb4_bin NOT NULL DEFAULT '',  `user_age` bigint DEFAULT NULL,  `user_email` longtext COLLATE utf8mb4_bin,  `user_phone` longtext COLLATE utf8mb4_bin,  `id` bigint unsigned NOT NULL AUTO_INCREMENT,  `created_at` datetime(3) DEFAULT NULL,  `updated_at` datetime(3) DEFAULT NULL,  `deleted_at` datetime(3) DEFAULT NULL,  PRIMARY KEY (`id`),  KEY `idx_my_gorm_user_deleted_at` (`deleted_at`)) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin使用例子package mainimport (	"encoding/json"	"fmt"	"gorm.io/driver/mysql"	"gorm.io/gorm")type OcFileCacheQuery struct {	Fileid int    `gorm:"column:fileid"`	Name   string `gorm"column:name"`	Path   string `gorm:"column:path"`}func connectDB(dsn string) (*gorm.DB, error) {	db, err := gorm.Open(mysql.Open(dsn), &amp;gorm.Config{})	return db, err}func main() {	dsn := "root:12345678@tcp(127.0.0.1:13301)/nextcloud?charset=utf8mb4&amp;parseTime=True&amp;loc=Local"	db, err := connectDB(dsn)	if err != nil {		fmt.Println("connect db failed,err:", err)		return	}	var fileCacheList []OcFileCacheQuery	whereFileId := 10	wherePath := "files/%"	LimitNum := 10	db.Table("oc_filecache").		Select("fileid,name,path").		Where("fileid &gt; ?", whereFileId).		Where("path LIKE ?", wherePath).		Limit(LimitNum).		Order("fileid desc").		Find(&amp;fileCacheList)	// 遍历结果	// fmt.Println("fileCacheList:", fileCacheList)	// fmt.Printf("fileCacheList type is %T\n", fileCacheList)	// fmt.Println("len is ", len(fileCacheList))	// fmt.Println("内容如下:")	// for _, v := range fileCacheList {	// 	fmt.Println(v)	// }	jsonBytes, err := json.Marshal(fileCacheList)	if err != nil {		fmt.Println("json marshal failed", err)		return	}	//fmt.Println(jsonBytes)	jsonStr := string(jsonBytes)	fmt.Println(jsonStr)	//fmt.Print(fileCacheList)	//fmt.Println(db, err)}参考资料  https://gorm.io/docs/]]></content>
      <categories>
        
          <category> Go </category>
        
      </categories>
      <tags>
        
          <tag> go </tag>
        
          <tag> gorm </tag>
        
          <tag> mysql </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Go 语言学习笔记]]></title>
      <url>/go/2025/09/18/go-study-note/</url>
      <content type="text"><![CDATA[数据类型Go 语言中的数据类型可以从不同维度进行分类。按组成结构​​，分为基本类型和复合类型。​​按赋值传递行为​​分为值类型和引用类型。基础类型构成程序的基础，不可再拆分，内存占用固定布尔var b1 boolb1 = trueb2 := false字符串string 和 byte[]，string可以直接转换成byte字节切片	var (		str1 string = "hello string"	)	str2 := "hello str2"	fmt.Println(str1, str2)整型11种内置整数类型：int8、uint8、int16、uint16、int32、uint32、int64、uint64、int、uint和uintptrvar a int = 10var i1, i2 int = 10, 20i3 := 30                  //默认类型是intfmt.Println(i1, i2, i3)fmt.Printf("i1 type is %T\n ", i1)fmt.Printf("i3 type is %T\n\n ", i3)浮点型两种内置浮点数类型：float32和float64。var f1 float32 = 3.14f2 := 3.14              //默认数据类型是float64fmt.Println(f1, f2)fmt.Printf("f2 type is %T\n ", f2)复数var cmp1 complex64 = 1 + 2icmp2 := 2 + 4i        //默认值是complex128fmt.Println(cmp1, cmp2)fmt.Printf("cmp2 type is %T\n", cmp2)零型var (  zb   bool  zs   string  zi   int  zf   float64  zcmp complex128)fmt.Println(zb, zs, zi, zf, zcmp)输出结果为false  0 0 (0+0i)常量复合类型由基本类型或其他复合类型组合而成，用于构建更复杂的数据结构数组  定义数组          var 变量名 [长度]类型        初始化定义数组          var 变量名 = [长度]类型{v1,v2,v3}      var 变量名 = […]类型{v1,v2,v3}      //数组var arr = [5]int{1, 2, 3, 4, 5}var arr1 [3]intvar arr2 = [3]int{1, 2, 3}arr3 := [3]int{4, 5, 6}var arr4 = [...]int{1, 2, 3}arr5 := [...]int{4, 5, 6}fmt.Println(arr1, arr2, arr3, arr4, arr5)for i, v := range arr2 {  fmt.Println(i, v)}// 冒泡排序for i := 0; i &lt; len(arr)-1; i++ {  for j := 0; j &lt; len(arr)-1-i; j++ {    if arr[j] &lt; arr[j+1] {      arr[j], arr[j+1] = arr[j+1], arr[j]    }    fmt.Println("aa:", arr)  }  fmt.Println("aaa:", arr)}fmt.Println(arr)//多维数组定义和遍历var arrM3 = [3][2]int{ {1, 2}, {3, 4}, {5, 6}}for i := 0; i &lt; len(arrM3); i++ {  for j := 0; j &lt; len(arrM3[i]); j++ {    fmt.Printf("%d ", arrM3[i][j])  }}for _, val := range arrM3 {  for index2, val2 := range val {    fmt.Printf("index is %d,val is %d \n", index2, val2)  }}切片引用类型  定义切片          var 变量名 []类型，不需要指定长度。      变量名 := make([]int,len,cap)，这种需要合理预估切片容量大小，如果预估过大会造成内存浪费，预估准确会提升性能。        var slice1 []intslice2 := []int{1, 2, 3}var slice3 = make([]int, 0)slice4 := make([]int, 0)fmt.Println(slice1, slice2, slice3, slice4)fmt.Printf("slice1 type is %T\nslice2 type is %T\n", slice1, slice2)fmt.Printf("slice1 type is %T\n", slice1)fmt.Println(slice1 == nil)slice1 = append(slice1, 1)slice1 = append(slice1, 2, 3, 4)fmt.Println(slice1 == nil)fmt.Println(slice1)                      切片常用操作          添加，append      截取，slice[start:end]，start或者end都可以省略      复制，copy(目标切片，源切片)，复制覆盖同位置的元素，不会改变切片的长度。      删除,slice[:2],删除第二个以后所有的元素，slice[2:]，删除第二个和前面的元素        slice1 := []int{1, 2, 3}slice2 := []int{4, 5, 6}slice1 = append(slice1, 7)//slice1 = slice1[:2]copy(slice1, slice2)fmt.Println(slice1, slice2)                集合、映射              定义方式          map[键的类型]值的类型       //定义一个空集合、映射。ma := map[string]int{}ma["a"] = 1fmt.Println(ma)//初始化定义一个非空集合、映射。m1 := map[string]int{"a": 1, "b": 2}//定义一个空集合、映射。m2 := make(map[string]string)//m2["a"] = 1m2["b"] = "hello"//m2[3] = 3.14m2["name"] = "tom"m2["age"] = "20"m2["city"] = "beijing"delete(m2, "city")//m2["city"] = "shanghai"//将json字符串转换成map集合。var j stringj = `{"infos":[{"name":"tom","age":20,"city":"beijing"},{"name":"jack","age":22,"city":"shanghai"}]}`fmt.Println(j)var m3 = map[string]any{}json.Unmarshal([]byte(j), &amp;m3)for key, val := range m3 {  fmt.Println("key is ", key)  fmt.Println("val is ", val)  //valSlice := val.([]interface{})  //valSlice := val.([]any)  valSlice := val.([]interface{})  for index, val2 := range valSlice {    fmt.Println("index is ", index)    fmt.Println("val2 is ", val2)    valMap := val2.(map[string]any)    for key3, val3 := range valMap {      fmt.Printf("key3 is %s,val3 is %v \n", key3, val3)    }  }}函数func sum(a,b int) int{  return a+b}func main(){  sumInt := sum(1,2)}方法函数和方法的区别是方法有一个类型接收者。type Age intfunc (age Age) Hello() {	fmt.Println("hello", age)}func main(){  age := Age(10)  age.Hello}结构体type Book struct {	Name   string	Price  float64	Author string	Page   int}//结构体定义方法func (b Book) HelloName() {	fmt.Println("book name is ", b.Name)}func (b Book) Pages() int {	return b.Page}func (b *Book) SetPages(page int) int {	b.Page = page	return b.Page}function main(){  Book1 := Book{Name: "Go",Price: 66.6, Author: "tom"}  Book1.HelloName()  var Book1 Book	Book1.SetPages(200)	pages := Book1.Pages()	fmt.Println(pages)	return}接口  接口的定义  接口的定义与结构体稍微有些差别，虽然都以type关键字开始，但接口的关键字是interface，表示定义的类型是一个接口。type Stringer interface {  String() string}  接口的实现  接口的实现者必须是一个具体的类型，以person结构体为例，让它来实现Stringer接口，如下面的代码所示type Stringer interface {  String() string}type Address struct {    province string    city string}type Person struct{  Name String  Age int  Address Address}func (p Person) String() string {  return fmt.Sprintf("the name is %s,age is %d",p.name,p.age)}通道​​不要在同一个 goroutine 中，对无缓冲 channel 顺序执行先接收后发送或先发送后接收的操作​​，这会导致该 goroutine 阻塞，从而使后续的配对操作没有机会执行。务必让它们在两个不同的 goroutine 中并发执行。func main(){ch3 := make(chan int)go func() {  ch3 &lt;- 100}()ch100 := &lt;-ch3fmt.Println("ch100 is ", ch100)returnch2 := make(chan int, 1)  //带缓冲区的通道ch2 &lt;- 1//ch2 &lt;- 2cha1 := &lt;-ch2//cha2 := &lt;-ch2fmt.Println(cha1)return}值类型​​赋值和传参时复制整个数据的副本​​，操作新副本不会影响原数据。所有​​基本类型​​、​​数组 (array)​​、​​结构体 (struct)​​引用类型​​赋值和传参时复制数据的引用（内存地址）​​，多个变量共享同一底层数据，修改会相互影响。​​切片 (slice)​​、​​映射 (map)​​、​​通道 (channel)​​、​​函数 (function)​​、​​接口 (interface)​​指针指针的本质是存储一个​​内存地址​​。理论上，任何类型的变量都有其内存地址，因此几乎​​所有数据类型​​（包括所有基本类型和复合类型）都可以有对应的指针类型。  函数参数传递默认是​​值传递​​，这意味着传递的是变量的副本。当参数是大型结构体或数组时，直接传值会导致显著的内存拷贝开销，影响性能。使用指针传递可以有效避免这种不必要的复制，因为传递的只是一个内存地址（在 64 位系统上通常是 8 字节），无论原对象有多大，开销几乎不变。makemake函数是专门用于初始化​​切片（slice）​​、​​映射（map）​​ 和​​通道（channel）​​ 这三种内置的引用类型的内置函数。它会对这些类型进行必要的内存分配和初始化，使其立即可用。  slice 切片package mainimport "fmt"type Person struct {    Name string    Age  int}func main() {    // 使用 make 初始化一个长度为 3 的 *Person 切片（指针切片）    people := make([]*Person, 3) // 长度和容量均为 3    fmt.Printf("初始化后: %v\n", people) // 输出: [&lt;nil&gt; &lt;nil&gt; &lt;nil&gt;]    // 为切片中的每个指针元素分配具体的 Person 实例    for i := 0; i &lt; len(people); i++ {        people[i] = &amp;Person{            Name: fmt.Sprintf("Person%d", i+1),            Age:  20 + i,        }    }    // 现在可以安全地访问和操作    for _, p := range people {        fmt.Printf("Name: %s, Age: %d\n", p.Name, p.Age)    }}  map集合映射package mainimport "fmt"func main() {    // 使用 make 初始化一个键为 string, 值为 *int 的映射    scoreMap := make(map[string]*int, 5) // 初始容量提示为 5    // 准备一些数据    scores := []int{100, 95, 88}    names := []string{"Alice", "Bob", "Charlie"}    // 将指针指向的分数存入映射    for i := 0; i &lt; len(scores); i++ {        // 注意：不能直接使用 &amp;scores[i] 如果 scores 是切片且后续可能修改或扩容        // 更安全的做法是创建变量的地址，或确保切片不再修改        score := scores[i] // 创建副本，取其地址        scoreMap[names[i]] = &amp;score    }    // 遍历映射，打印键和指针指向的值    for name, ptr := range scoreMap {        fmt.Printf("Name: %s, Score: %d (指针地址: %p)\n", name, *ptr, ptr)    }    // 通过指针修改映射中的值    if ptr, exists := scoreMap["Alice"]; exists {        *ptr = 99 // 修改 Alice 的分数        fmt.Println("修改后 Alice 的分数:", *scoreMap["Alice"])    }}  chan 通道package mainimport (    "fmt"    "time")func main() {    // 使用 make 创建一个能缓冲 2 个 int 指针的通道    msgChan := make(chan *int, 2)    go func() {        // 在 goroutine 中创建一些整数并发送其指针到通道        for i := 0; i &lt; 3; i++ {            num := i * 10 // 创建整数            fmt.Printf("发送: %d (地址: %p)\n", num, &amp;num)            msgChan &lt;- &amp;num // 发送整数的指针到通道            time.Sleep(100 * time.Millisecond)        }        close(msgChan) // 发送完毕后关闭通道    }()    // 从通道接收整数的指针并打印其值    fmt.Println("接收数据:")    for receivedPtr := range msgChan {        fmt.Printf("接收: %d (来自地址: %p)\n", *receivedPtr, receivedPtr)    }}newnew函数常用来声明非引用数据类型如基本类型、复合类型的变量。// 1. 基本数据类型var intPtr *int = new(int)           // *int, 指向 0var floatPtr *float64 = new(float64) // *float64, 指向 0.0var boolPtr *bool = new(bool)         // *bool, 指向 falsevar strPtr *string = new(string)     // *string, 指向 ""// 2. 数组 (array)var arrPtr *[3]int = new([3]int) // *[3]int, 指向 [3]int{0, 0, 0}// 3. 结构体 (struct)type Person struct {    Name string    Age  int}var structPtr *Person = new(Person) // *Person, 指向 Person{"", 0}// 4. 切片 (slice) - 注意：new 只为切片头结构分配了内存，其底层数组为 nilvar slicePtr *[]int = new([]int) // *[]int, 指向一个 nil 切片// 5. 集合 (map) - 注意：new 只为 map 指针分配了内存，其底层哈希结构为 nilvar mapPtr *map[string]int = new(map[string]int) // *map[string]int, 指向一个 nil map// 6. 通道 (channel) - 注意：new 只为 channel 指针分配了内存，其底层通道结构为 nilvar chanPtr *chan int = new(chan int) // *chan int, 指向一个 nil channel// 7. 指针的指针var ptrToPtr **int = new(*int) // **int, 指向一个 *int 类型的指针，该指针本身为 nil// 打印初始零值fmt.Println("基本类型零值:", *intPtr, *floatPtr, *boolPtr, *strPtr)fmt.Println("数组零值:", *arrPtr)fmt.Println("结构体零值:", *structPtr)fmt.Println("切片指针的值 (底层数组为nil):", *slicePtr) // 输出 []fmt.Println("映射指针的值 (底层映射为nil):", *mapPtr)   // 输出 map[]fmt.Println("通道指针的值 (底层通道为nil):", *chanPtr)   // 输出 &lt;nil&gt;fmt.Println("指针的指针的值 (指向的指针为nil):", *ptrToPtr) // 输出 &lt;nil&gt;// 重要说明：对于引用类型（slice, map, channel），new 仅分配了指针本身的内存，// 并没有初始化其底层数据结构。直接使用（如赋值、发送数据）会导致 panic。// 例如：// (*mapPtr)["key"] = 1 // 这行会引发 panic: assignment to entry in nil map// *slicePtr = append(*slicePtr, 1) // 这行可以执行，因为 append 会处理 nil slice，但通常不这样用。// 正确初始化引用类型应使用 make 函数：*slicePtr = make([]int, 0, 10) // 初始化切片底层数组*mapPtr = make(map[string]int)  // 初始化映射*chanPtr = make(chan int, 5)    // 初始化通道// 初始化后即可安全使用(*mapPtr)["key"] = 100*slicePtr = append(*slicePtr, 1, 2, 3)go func() { *chanPtr &lt;- 42 }()fmt.Println("初始化后的映射:", *mapPtr)fmt.Println("初始化后的切片:", *slicePtr)fmt.Println("从通道接收值:", &lt;-*chanPtr)指针在函数中的应用package mainimport "fmt"// increment 函数接收一个指向整数的指针，并将其指向的值加1func increment(ptr *int) {    *ptr = *ptr + 1 // 通过指针修改原始值}func main() {    count := 10    fmt.Println("原始值:", count) // 输出: 原始值: 10        increment(&amp;count)          // 传递 count 的地址    fmt.Println("调用后:", count) // 输出: 调用后: 11}指针在方法中的应用package mainimport "fmt"type Person struct {    Name string    Age  int}// Birthday 方法使用指针接收者 *Person，用于增加年龄func (p *Person) Birthday() {    p.Age++ // 直接修改接收者 p 所指向的 Person 实例的 Age 字段    fmt.Printf("%s 过生日啦！现在年龄是 %d\n", p.Name, p.Age)}func main() {  person := Person{Name: "Alice", Age: 25}  fmt.Println("调用前:", person.Age) // 输出: 调用前: 25    person.Birthday()               // 调用方法，Go 会自动将 person 的地址传递给指针接收者  fmt.Println("调用后:", person.Age) // 输出: 调用后: 26    // 即使你有一个指针变量，调用方式也是一样的（Go 的语法糖）  ptr := &amp;person  ptr.Birthday()                  // 输出: Alice 过生日啦！现在年龄是 27  fmt.Println("通过指针调用后:", person.Age) // 输出: 通过指针调用后: 27}*号和&amp;符号声明变量为指针变量//指针intP1 := 100var intPointer *intintPointer = &amp;intP1intPointer2 := *intPointerfmt.Println(intPointer, *intPointer, intPointer2)type关键字//自定义类型（在基本类型基础上），使用大小驼峰，大驼峰代表导出，小驼峰只在包内。type MyInt inttype myInt int//结构体type ShoppingCart struct{}//接口type Formatter interface{}类型断言]]></content>
      <categories>
        
          <category> Go </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Redis]]></title>
      <url>/redis/2025/09/16/redis/</url>
      <content type="text"><![CDATA[Redis高频面试题  缓存穿透          问题描述        当查询Redis中没有数据时，该查询会下沉到数据库层，同时数据库层也没有该数据，当出现大量这种查询（或被恶意攻击）时，接口的访问全部透过Redis访问数据库，而数据库中也没有这些数据，我们称这种现象为“缓存穿透”。          解决方案                  在业务服务访问层对用户进行校验来判断是不是来自恶意用户的请求，比如对请求参数进行校验和检查一段时间内请求同一个服务的次数。          将数据库层有关数据的键存储到布隆过滤器中，以判断访问的键是否在底层的数据库中。如果在布隆过滤器中则查询缓存，如果缓存没有则再次查询MySQL数据库；如果布隆过滤器中没有，则直接返回我们预先规定好的结果即可。我们也可以把布隆过滤器的层级放到缓存下一层，当请求数据的时候先去缓存层获取。如果缓存里面有数据，就直接返回结果；如果缓存没有，就去布隆过滤器判断相关数据的键是否在布隆过滤器中，如果在就继续查询MySQL数据库，如果不存在就直接返回，不在进行数据库层级的查询。                      缓存击穿          问题描述        缓存击穿和缓存穿透从名词上很难区分开，他们的区别主要是“穿透”表示底层数据库层没有数据而且缓存层内也没有数据，而“击穿”表示底层数据库有数据但是缓存层内没有数据。          解决方案                  热点键的过期时间设置为永不过期          利用互斥锁保证同一时刻只有一个客户端可以查询底层数据库的数据，一旦查到数据就缓存至Redis内，以避免其他大量请求同时穿过Redis去访问底层数据库。                          缓存雪崩          问题描述缓存击穿说的是热点数据过期，缓存雪崩说的是大面积的数据过期。缓存雪崩是指Redis中大量的键几乎同时过期，然后大量并发的查询穿过Redis冲击到底层数据库上，此时数据库的负载压力会增大。相比于缓存击穿，缓存雪崩更容易发生。      解决方案                  在可接受的时间范围内随机设置键的过期时间，分撒键的过期时间，以防止大量的键在同一时刻过期。          键的过期时间设置永不过期。            Redis 持久化方案                                RDB  AOF  RDB+AOF# 1. RDB 配置 - 根据你的数据重要性和写入频繁程度调整save 900 1                      # 900秒（15分钟）内至少1个key发生变化save 300 10                     # 300秒（5分钟）内至少10个key发生变化save 60 10000                   # 60秒内至少10000个key发生变化dbfilename dump.rdb             # RDB 文件名rdbcompression yes               # 开启RDB文件压缩，节省空间rdbchecksum yes                 # 开启RDB文件校验，保证数据完整性stop-writes-on-bgsave-error yes # 后台保存出错时停止写入，防止数据不一致# 2. AOF 配置 - 混合持久化的基础，必须开启appendonly yes                  # 启用AOF持久化appendfilename "appendonly.aof" # AOF文件名appendfsync everysec            # 每秒同步，性能与安全的良好平衡# 3. AOF 重写配置 - 防止AOF文件无限膨胀auto-aof-rewrite-percentage 100  # 当前AOF文件比上次重写后大小增长100%时触发auto-aof-rewrite-min-size 64mb   # AOF文件最小达到64MB才触发重写# 4. 启用混合持久化 (Redis 4.0+)aof-use-rdb-preamble yes# 5. 通用配置dir /path/to/your/redis/data    # 设置持久化文件存储目录，确保磁盘空间充足Redis高可用方案  主从1台主、1台从  哨兵模式1台主、2台从、3台哨兵(部署到每台主从)  集群模式3太主、3台从]]></content>
      <categories>
        
          <category> Redis </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[VSCode如何配置go开发环境]]></title>
      <url>/go/2025/08/01/go-dev-env/</url>
      <content type="text"><![CDATA[vscode配置Go开发环境检查Go是否安装bash-3.2$ go versiongo version go1.24.1 darwin/amd64VSCode安装Go相关开发调试的工具Command/Ctrl+Shift+P快捷键弹出命令面板窗口选择=》Go:Install/Update Tools检查Go开发调试相关工具安装是否成功bash-3.2$ go env|grep -E "GOPATH"GOPATH='/Users/zhaoqhu/go'bash-3.2$ ls -alt /Users/zhaoqhu/go/bin/total 243744-rwxr-xr-x   1 zhaoqhu  staff  15396912  8  1 16:43 staticcheck-rwxr-xr-x   1 zhaoqhu  staff  21008256  8  1 16:43 dlv-rwxr-xr-x   1 zhaoqhu  staff   8835376  8  1 16:42 goplay-rwxr-xr-x   1 zhaoqhu  staff   7168976  8  1 16:42 impl-rwxr-xr-x   1 zhaoqhu  staff  13199952  8  1 16:42 gotestsdrwxr-xr-x   6 zhaoqhu  staff       192  8  1 14:56 ..drwxr-xr-x  10 zhaoqhu  staff       320  7 22 16:30 .-rwxr-xr-x   1 zhaoqhu  staff  18287600  7 12 13:16 godoc-rwxr-xr-x   1 zhaoqhu  staff   4149888  3 26 13:49 gomodifytags-rwxr-xr-x   1 zhaoqhu  staff  36730976  3 26 13:49 gopls安装Go扩展Command/Ctrl+Shift+X快捷键，打开扩展商店运行和调试创建launch.json文件{    // 使用 IntelliSense 了解相关属性。     // 悬停以查看现有属性的描述。    // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387    "version": "0.2.0",    "configurations": [    {        "name": "Launch Package",        "type": "go",        "request": "launch",        "mode": "auto",        "program": "${workspaceFolder}"    },    {        "name": "Launch Package test",        "type": "go",        "request": "launch",        "mode": "auto",        "program": "${workspaceFolder}/test"    },    {        "name": "Launch Package chapter1",        "type": "go",        "request": "launch",        "mode": "auto",        "program": "${workspaceFolder}/chapter1/channels"    },    ]}验证调试bash-3.2$ curl http://127.0.0.1:8080/ping{"message":"pong"}bash-3.2$ curl http://127.0.0.1:8080/hello{"msg":"hello"}bash-3.2$ ]]></content>
      <categories>
        
          <category> Go </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Php High Level]]></title>
      <url>/2024/03/10/php-high-level/</url>
      <content type="text"><![CDATA[分布式事务最大努力通知案例分析在第三方支付中，例如支付宝，或者微信，对于订单请求，第三方支付系统采用的是消息同步返回，异步通知+主动补偿查询的补偿机制。由于互联网通信的不可靠性，例如网络故障、服务器故障、应用bug等因素的影响，不管是同步返回、异步通知、主动查询报文都可能出现超时无响应、报文丢失等情况，所以像支付业务、对结果的通知、一般采用几种方案结合的补偿机制，不能完全依赖某一种机制。例如一个支付结果的通知，一方面会在支付页面跳转时候返回支付结果（一般只用作前端展示使用，非最终状态），同时会采用后台异步通知机制（有前台、后台通知的，以后台异步通知结果为准），但由于前台跳转、后台结果通知可能失效，因此还以定时补单+请求方主动查询接口作为辅助手段。常见的补单操作，任务调度策略一般设定30秒、60秒、3分钟、6分钟、10分钟调度多次（以自己业务需要），如果调度接受到响应确认报文，补单成功。则终止对应订单的调度任务；如果超过补单上限次数，则停止补单，避免无谓的资源浪费。请求端随时可以发起请求报文查询对应订单的状态。## 最大努力通知型### 实现  1、业务活动的主动方，在完成业务处理之后，向业务活动的被动房发送消息，被动方需主动响应正确消息，否则根据定时策略，最大努力通知。  2、业务活动的被动方（电商平台）也可以向业务活动主动方（支付宝平台）查询，恢复丢失的业务消息。  ### 约束  被动方的处理结果不能影响主动方的处理结果  ### 成本  业务查询与校对系统的建设成本  ### 使用范围  对业务最终一致性的时间敏感度低  跨企业的业务活动  ### 方案特点  业务活动的主动方在完成业务处理后，向业务活动被动方发送通知消息（允许消息丢失）  主动方可以设置时间阶梯通知规则，在通知失败后按规则重复通知，直到通知N次后，主动方提供校队查询接口给被动方按需校队查询，用于恢复丢失的业务消息  ### 应用案例  银行通知、商户通知等（各大交易业务平台间的商户通知：多次通知、查询校对、对账文件）## 了解docker并且快速配置RabbitMQ### Docker是什么？  Docker是一个开源的应用容器引擎，你可以将其理解为一个轻量级的虚拟机，开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的Linux机器上，只要有了Docker，用户便不在需要为这些应用配置其所需的特有环境了，也不需要为这些应用统一环境了  ### 为什么要使用Docker，Docker的好处是什么？  可以认为Docker是一个通用安装程序，简单来说，利用Docker容器，可以将任何一个或者多个程序封装起来，并提供标准的管理接口，因为使用了容器，所以可以很方便的把生产环境和开发环境分开，互不影响，这样，开发人员负责维护内容，并使用Docker进行封装，系统管理人员利用Docker的标准接口进行部署和管理。Docker的主要用途，目前有三大类。  1）提供一致性的环境。比如，本地测试他人的软件、持续集成的时候提供单元测试和构建环境。  2）提供弹性的云服务。因为Docker容器可以随开随关，很适合动态扩容和缩容。  3）组件微服务架构，通过多个容器，一台机器可以跑多个服务，因此在本机就可以模拟出微服务架构。### 一、Docker安装   CentOS  1、更新update到最新的版本  yum update  2、安装docker  yum -y install docker  3、启动docker  systemctl start docker  4、加入开启自启  systemctl enable docker### 二、Docker参数说明  启动会自动搜索 rabbitMQ]]></content>
      <categories>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Php Config]]></title>
      <url>/2024/03/10/php-config/</url>
      <content type="text"><![CDATA[./configure  --prefix=/usr/local/php7-15 --enable-opcache --with-config-file-path=/usr/local/php7-15/etc --with-mysql=mysqlnd --with-mysqli=mysqlnd --with-pdo-mysql=mysqlnd --enable-fpm --enable-fastcgi --enable-static --enable-inline-optimization --enable-sockets --enable-wddx --enable-zip --enable-calendar --enable-bcmath --enable-soap --with-zlib --with-iconv=/usr/local --with-gd --with-xmlrpc --enable-mbstring --without-sqlite --with-curl --enable-ftp --with-freetype-dir=/usr/local/Cellar/freetype/2.12.1 --with-jpeg-dir=/usr/local/Cellar/jpeg-turbo/2.1.4 --with-webp-dir=/usr/local/Cellar/webp/1.2.4 --with-xpm-dir=/usr/local/Cellar/libxpm/3.5.14 --with-png-dir=/usr/local/Cellar/libpng/1.6.39 --with-zlib-dir=/usr/local/Cellar/zlib/1.2.13 --with-iconv=/usr/local/Cellar/libiconv/1.17 --disable-ipv6 --disable-debug --disable-maintainer-zts --disable-safe-mode --disable-fileinfochmod -R 7777 ./index.html ./caches ./html ./uploadfile ./phpsso_server/caches ./phpsso_server/uploadfilecd /home/zhaoqhu/php-srcwget https://www.php.net/distributions/php-7.4.16.tar.gztar -zxvf ./php-7.4.16.tar.gzexport PKG_CONFIG_PATH="/usr/local/opt/libedit/lib/pkgconfig"export PKG_CONFIG_PATH="/usr/local/opt/libsodium/lib/pkgconfig"./configure \–with-iconv=/usr/local/opt/libiconv \–enable-fpm \–prefix=/usr/local/php7-416 \–with-config-file-path=/usr/local/php7-416/etc \–with-config-file-scan-dir=/usr/local/php7-416/etc/conf.d \–enable-option-checking=fatal \–with-mhash \–with-pic \–enable-ftp \–enable-mbstring \–enable-mysqlnd \–with-password-argon2 \–with-sodium \–with-curl \–with-libedit \–with-openssl \–with-zlib \–with-pear \–with-fpm-user=www-data \–with-fpm-group=www-data \–disable-cgi \# 扩展安装## apcu/usr/local/php7-416/bin/php/usr/local/php7-416/sbin/php-fpm./pecl install apcush-3.2# ../../php7-416/bin/pecl install apcu../../php7-416/bin/pecl install https://pecl.php.net/get/apcu-5.1.22.tgzcp ~zhaoqinghu/Desktop/83-2000/etc/php/conf.d/docker-php-ext-apcu.ini ./## bcmath/usr/local/php7-416/bin/phpize./configure   –with-php-config=/usr/local/php7-416/bin/php-configmakemake installcp ~zhaoqinghu/Desktop/83-2000/etc/php/conf.d/docker-php-ext-bcmath.ini ./killall -9 php-fpm## exif/usr/local/php7-416/bin/phpize./configure   –with-php-config=/usr/local/php7-416/bin/php-configmake &amp;&amp; make installsh-3.2# cp ~zhaoqinghu/Desktop/83-2000/etc/php/conf.d/docker-php-ext-exif.ini ./sh-3.2# killall -9 php-fpmsh-3.2# /usr/local/php7-416/sbin/php-fpm## gdcd ext/gd//usr/local/php7-416/bin/phpize./configure   –with-php-config=/usr/local/php7-416/bin/php-config –with-freetypemake &amp;&amp; make installcp ~zhaoqinghu/Desktop/83-2000/etc/php/conf.d/docker-php-ext-gd.ini ./## gmpcd ext/gmp//usr/local/php7-416/bin/phpize./configure   –with-php-config=/usr/local/php7-416/bin/php-configchecking for __gmpz_rootrem in -lgmp… noconfigure: error: GNU MP Library version 4.2 or greater required.brew install gmpmake &amp;&amp; make installsh-3.2# cp ~zhaoqinghu/Desktop/83-2000/etc/php/conf.d/docker-php-ext-gmp.ini ./sh-3.2# killall -9 php-fpmsh-3.2# /usr/local/php7-416/sbin/php-fpm## imageickhttps://pecl.php.net/get/imagick-3.7.0.tgzsh-3.2# pwd/usr/local/php-src-7.4.16/pecl-srcsh-3.2# cp ~zhaoqinghu/Downloads/imagick-3.7.0.tgz ./sh-3.2# /usr/local/php7-416/bin/pecl install imagick-3.7.0.tgz 33 source files, buildingconfigure: error: not found. Please provide a path to MagickWand-config or Wand-config program.ERROR: `/private/var/tmp/pear/temp/imagick/configure –with-php-config=/usr/local/php7-416/bin/php-config –with-imagick’ failedbrew install imagemagicksh-3.2# cp ~zhaoqinghu/Desktop/83-2000/etc/php/conf.d/docker-php-ext-imagick.ini ./sh-3.2# killall -9 php-fpmsh-3.2# /usr/local/php7-416/sbin/php-fpm## intl安装失败cd intl/usr/local/php7-416/bin/phpize./configure   –with-php-config=/usr/local/php7-416/bin/php-configchecking for icu-uc &gt;= 50.1 icu-io icu-i18n… noconfigure: error: Package requirements (icu-uc &gt;= 50.1 icu-io icu-i18n) were not met:export PKG_CONFIG_PATH=”$PKG_CONFIG_PATH:/usr/local/opt/icu4c/lib/pkgconfig”./configure   –with-php-config=/usr/local/php7-416/bin/php-configmake &amp;&amp; make install## ldap/usr/local/php7-416/bin/phpize./configure   –with-php-config=/usr/local/php7-416/bin/php-config –with-ldap=/usr/local/opt/openldapbrew install openldapexport PKG_CONFIG_PATH=”$PKG_CONFIG_PATH:/usr/local/opt/openldap/lib/pkgconfig”export LDFLAGS=”-L/usr/local/opt/openldap/lib”export CPPFLAGS=”-I/usr/local/opt/openldap/include”sh-3.2# cp ~zhaoqinghu/Desktop/83-2000/etc/php/conf.d/docker-php-ext-ldap.ini ./sh-3.2# killall -9 php-fpmsh-3.2# /usr/local/php7-416/sbin/php-fpm## memcached安装错误https://pecl.php.net/get/memcached-3.2.0.tgzcp ~zhaoqinghu/Downloads/memcached-3.2.0.tgz ./-3.2# cp ~zhaoqinghu/Downloads/memcached-3.2.0.tgz ./sh-3.2# /usr/local/php7-416/bin/pecl install memcached-3.2.0.tgz## opcache/usr/local/php7-416/bin/phpize./configure   –with-php-config=/usr/local/php7-416/bin/php-configmake &amp;&amp; make installcp ~zhaoqinghu/Desktop/83-2000/etc/php/conf.d/docker-php-ext-opcache.ini ./killall -9 php-fpm/usr/local/php7-416/sbin/php-fpm## pcntl/usr/local/php7-416/bin/phpize./configure   –with-php-config=/usr/local/php7-416/bin/php-configmake &amp;&amp; make installsh-3.2# cp ~zhaoqinghu/Desktop/83-2000/etc/php/conf.d/docker-php-ext-pcntl.ini ./sh-3.2# killall -9 php-fpmsh-3.2# /usr/local/php7-416/sbin/php-fpm## pdo_mysql/usr/local/php7-416/bin/phpize./configure   –with-php-config=/usr/local/php7-416/bin/php-configmake &amp;&amp; make install## pdo_pgsql暂时不安装## redishttps://pecl.php.net/get/redis-5.3.7.tgzsh-3.2# cp ~zhaoqinghu/Downloads/redis-5.3.7.tgz ./sh-3.2# /usr/local/php7-416/bin/pecl install redis-5.3.7.tgz 31 source files, buildingsh-3.2# cp ~zhaoqinghu/Desktop/83-2000/etc/php/conf.d/docker-php-ext-redis.ini ./sh-3.2# killall -9 php-fpmsh-3.2# /usr/local/php7-416/sbin/php-fpmsh-3.2### sodium/usr/local/php7-416/bin/phpize./configure   –with-php-config=/usr/local/php7-416/bin/php-configmake &amp;&amp; make install## zipbrew install libzipzhaoqinghu@zhaoqinghudeMacBook-Pro no-debug-non-zts-20190902 % chmod -R 777 /usr/local/lib/cmake chmod: Unable to change file mode on /usr/local/lib/cmake: Operation not permittedchmod: Unable to change file mode on /usr/local/lib/cmake/libxml2: Operation not permittedchmod: Unable to change file mode on /usr/local/lib/cmake/libxml2/libxml2-config.cmake: Operation not permittedzhaoqinghu@zhaoqinghudeMacBook-Pro no-debug-non-zts-20190902 % sudo chmod -R 777 /usr/local/lib/cmakezhaoqinghu@zhaoqinghudeMacBook-Pro no-debug-non-zts-20190902 %  brew link libzip                   Linking /usr/local/Cellar/libzip/1.9.2… 135 symlinks created./usr/local/php7-416/bin/phpize./configure   –with-php-config=/usr/local/php7-416/bin/php-configmake &amp;&amp; make installsh-3.2# cp ~zhaoqinghu/Desktop/83-2000/etc/php/conf.d/docker-php-ext-zip.ini ./sh-3.2# killall -9 php-fpmsh-3.2# /usr/local/php7-416/sbin/php-fpm## mysqlicd mysqli/ /usr/local/php7-416/bin/phpize ./configure   –with-php-config=/usr/local/php7-416/bin/php-config  make &amp;&amp; make install## xdebugsh-3.2# /usr/local/php7-416/bin/pecl install xdebug-3.2.0.tgz pecl/xdebug requires PHP (version &gt;= 8.0.0, version &lt;= 8.2.99), installed version is 7.4.16No valid packages foundinstall failedsh-3.2# cp ~zhaoqinghu/Downloads/xdebug-3.1.5.tgz ./sh-3.2# /usr/local/php7-416/bin/pecl install xdebug-3.1.5.tgz 93 source files, buildingrunning: phpizeConfiguring for:PHP Api Version:         20190902Zend Module Api No:      20190902Zend Extension Api No:   320190902sh-3.2# cat docker-php-ext-xdebug.ini zend_extension=xdebugxdebug.remote_handler = dbgpxdebug.remote_connect_back = 0xdebug.idekey = dockerxdebug.mode = debugxdebug.start_with_request = yesxdebug.client_port = 9003xdebug.client_host = 127.0.0.1xdebug.log = /tmp/xdebug.log```参考资料https://blog.csdn.net/ligaofeng/article/details/105819374https://www.liuvv.com/p/ad42ac48.htmlhttps://mirrors.tuna.tsinghua.edu.cn/homebrew-bottles/https://mirrors.tuna.tsinghua.edu.cn/homebrew-bottles/icu4c-71.1.big_sur.bottle.tar.gz]]></content>
      <categories>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Rabbitmq]]></title>
      <url>/2022/12/06/rabbitmq/</url>
      <content type="text"><![CDATA[Mac安装rabbitmq使用homebrew安装brew updatebrew install rabbitmq启动rabbitmq服务% pwd/usr/local/Cellar/rabbitmq/3.11.4/sbin% lsrabbitmq-defaults	rabbitmq-queues		rabbitmq-upgraderabbitmq-diagnostics	rabbitmq-server		rabbitmqadminrabbitmq-env		rabbitmq-streams	rabbitmqctlrabbitmq-plugins	rabbitmq-tanzu% /usr/local/Cellar/rabbitmq/3.11.4/sbin/rabbitmq-server # 启动服务启动management 插件网页管理器% /usr/local/Cellar/rabbitmq/3.11.4/sbin/rabbitmq-plugins enable rabbitmq_management访问Managementhttp://localhost:15672/默认账号:guest默认密码:guestphp安装amqp扩展amqp扩展依赖rabbitmq-chomebrew安装rabbitmq-cbrew install rabbitmq-c由于国内网络原因，使用pecl在线安装可能会失败，如果失败可以先将安装包现在到本地，然后在使用本地的安装包下载curl -O https://pecl.php.net/get/amqp-1.11.0.tgz% pwd/usr/local/php7-15/bin% ./pecl install /Users/zhaoqinghu/Downloads/amqp-1.11.0.tgz% Set the path to librabbitmq install prefix [autodetect] : /usr/local/Cellar/rabbitmq-c/0.11.0 #输入rabbitmq-c的安装位置Installing '/usr/local/php7-15/lib/php/extensions/no-debug-non-zts-20160303/amqp.so'install ok: channel://pecl.php.net/amqp-1.11.0configuration option "php_ini" is not set to php.ini locationYou should add "extension=amqp.so" to php.inish-3.2#参考资料https://www.rabbitmq.com/install-homebrew.htmlhttps://formulae.brew.sh/formula/rabbitmq#default]]></content>
      <categories>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[rabbitmq生产者和消费者]]></title>
      <url>/%E4%B8%AD%E9%97%B4%E4%BB%B6/2022/12/03/amqp/</url>
      <content type="text"><![CDATA[组件间关系与协作流程​消息发送流程​​  生产者建立连接和通道​​  生产者​​声明交换机（如 order_exchange）和队列（如 order_queue）。  生产者​​通过 queueBind将队列绑定到交换机，指定路由键（如 order.created）。  生产者​​构造消息，设置路由键和元数据。  生产者​​通过 basicPublish将消息发送到交换机。  交换机​​根据路由键和绑定规则，将消息路由到目标队列。  息持久化存储在队列中，等待消费者消费。​​消息消费流程​​  消费者建立连接和通道  ​消费者​​声明队列（确保队列存在）。  ​消费者​​通过 basicConsume订阅队列，监听消息。  消息到达队列后，Broker 推送或消费者拉取消息。  ​消费者​​处理消息，发送确认（ACK）或拒绝（NACK）。  消息确认后从队列删除，或根据配置重新入队。消息生产者-交换机-topic&lt;?php$connArgs = array(     'host'=&gt;'localhost',    'port'=&gt; '5672',    'login'=&gt;'guest',    'password'=&gt;'guest',    'vhost' =&gt;'/');$conn = new AMQPConnection($connArgs);$conn-&gt;connect();$channel = new AMQPChannel($conn);$eName = 'e.zhaoqhu.topic'; //交换机名 //$q_name = 'q_linvo'; //无需队列名 $routeKey = 'route.key.zhaoqhu.login.error'; //路由key $routeKeyB = 'route.key.zhaoqhu.mail.error'; //路由key $routeKeyC = 'route.key.zhaoqhu.register.error';//创建交换机对象    $ex = new AMQPExchange($channel);   $ex-&gt;setName($eName);//设置交换机类型//$ex-&gt;setType(AMQP_EX_TYPE_DIRECT);$ex-&gt;setType(AMQP_EX_TYPE_TOPIC);//数据持久化类型$ex-&gt;setFlags(AMQP_DURABLE);//var_dump($ex);die;//date_default_timezone_set("Asia/Shanghai");//发送消息for($i=0; $i&lt;5; ++$i){     sleep(0.1);//休眠1秒    //消息内容     //$message = "Hello Rabbitmq zhaoqhu route.key.zhaoqhu.register.error 2222!".date("h:i:sa");    $message = [        'exchange'=&gt;'e.zhaoqhu.topic',        'routeKey'=&gt;'route.key.zhaoqhu.register.error',        'msg'=&gt;'hello2222route.key.zhaoqhu.register.error'    ];    $message = json_encode($message);   // echo "Send Message:".$ex-&gt;publish($message, $routeKeyC)."\n";  //    content_type	 	text/plain// content_encoding	 	NULL// message_id	 	NULL// user_id	 	NULL// app_id	 	NULL// delivery_mode	 	NULL// priority	 	NULL// timestamp	 	NULL// expiration	 	NULL// type	 	NULL// reply_to    $attr = ['content_type'=&gt;'text/plain',   'content_encoding'=&gt;'utf-8',   'message_id'=&gt;100,   'user_id'=&gt;"guest",   //'app_id'=&gt;'',   //'delivery_mode'=&gt;'',   //'priority'=&gt;'',   //'timestamp'=&gt;'',   //'expiration'=&gt;'',   //'type'=&gt;'',   //'reply_to'=&gt;'',   ];   echo "Send Message:".$ex-&gt;publish($message, $routeKeyC,AMQP_MANDATORY,$attr)."\n";  } die;for($i=0; $i&lt;5; ++$i){     sleep(0.1);//休眠1秒    //消息内容     $message = "Hello Rabbitmq zhaoqhu route.key.zhaoqhu.login.error 2222!".date("h:i:sa");       echo "Send Message:".$ex-&gt;publish($message, $routeKey)."\n";  } for($i=0; $i&lt;5; ++$i){     sleep(0.1);//休眠1秒    //消息内容     $message = "Hello Rabbitmq zhaoqhu route.key.zhaoqhu.mail.error 2222!".date("h:i:sa");       echo "Send Message:".$ex-&gt;publish($message, $routeKeyB)."\n";  } $conn-&gt;disconnect();echo "sucess:end";?&gt;消息消费者&lt;?php$connArgs = array(     'host'=&gt;'localhost',    'port'=&gt; '5672',    'login'=&gt;'guest',    'password'=&gt;'guest',    'vhost' =&gt;'/');$e_name = 'e.zhaoqhu.topic'; //交换机名 $q_name = 'q.zhaoqhu'; //队列名 $k_route = 'route.key.zhaoqhu.login.error'; //路由key $k_route = '#.error'; //路由key  //创建连接和channel $conn = new AMQPConnection($connArgs);   if (!$conn-&gt;connect()) {       die("Cannot connect to the broker!\n");   }   $channel = new AMQPChannel($conn);    //创建交换机    $ex = new AMQPExchange($channel);   $ex-&gt;setName($e_name); $ex-&gt;setType(AMQP_EX_TYPE_TOPIC); //topic类型  $ex-&gt;setFlags(AMQP_DURABLE); //持久化 try {   // echo "Exchange Status:".$ex-&gt;declare()."\n";     echo "Exchange Status:".$ex-&gt;declareExchange()."\n";  } catch (\Throwable $th) {    var_dump(1111,$th-&gt;getMessage());die;}    //创建队列    $q = new AMQPQueue($channel); $q-&gt;setName($q_name);   $q-&gt;setFlags(AMQP_DURABLE); //持久化  //echo "Message Total:".$q-&gt;declare()."\n";   echo "Message Total:".$q-&gt;declareQueue()."\n";    //绑定交换机与队列，并指定路由键 echo 'Queue Bind: '.$q-&gt;bind($e_name, $k_route)."\n";  //阻塞模式接收消息 echo "Message:\n";   while(True){     $q-&gt;consume('processMessage');    //$q-&gt;consume('processMessage', AMQP_AUTOACK); //自动ACK应答      sleep(1);} $conn-&gt;disconnect();/** * 消费回调函数 * 处理消息 */ function processMessage($envelope, $queue) {     $msg = $envelope-&gt;getBody();     echo $msg."\n"; //处理消息     $queue-&gt;ack($envelope-&gt;getDeliveryTag()); //手动发送ACK应答 }?&gt;参考资料http://docs.php.net/manual/da/book.amqp.php]]></content>
      <categories>
        
          <category> 中间件 </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[mysql启动]]></title>
      <url>/2021/11/14/mysql-init/</url>
      <content type="text"><![CDATA[查看mysql配置文件/usr/local/Cellar/mysql/5.6.23/bin/mysql            /usr/local/Cellar/mysql/5.6.23/bin/mysql –help      grep ‘my.cnf’      cat /usr/local/etc/my.cnf;            ps aux      grep mysql      grep ‘my.cnf’      ]]></content>
      <categories>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[php使用kafka]]></title>
      <url>/php/2021/09/12/php-kafka/</url>
      <content type="text"><![CDATA[  kafka基础架构和消息队列原理剖析  生产者与消费者模式原理解读  kafka flollwer如何与leader同步数据？  如何保证消息的幂等性、确认消费，避免重复消费  kafka的确认机制是如何保证的  必备kafka高可用集群搭建方案zookeeper Serverkafka队列使用场景京东618，秒杀场景。队列的作用解耦系统，异步，限流，消峰。服务器的性能，10w qps618活动时达到，200w qps使用队列把200w qps，分解到10w qps，保障系统正常的使用。异步生产者与消费者模式原理解读zookeeper 负责管理kafka集群，比如kafka1挂掉，zookeeper负责自动链接到kafka2kafka的数据通过zookeeperkafka 1kafka 2kafka 3消息被确认消费？Redis 队列 中小型没有持久化的内容 性能支持每秒10万级别吞吐量没问题。kafka 大型的系统每秒25万级别的吞吐量批量读写MMAP 内存映射php 使用kafkacomposer kafkacomposer require nmred/kafka-phpuse Kafkaclass KafkaController extends Controller{    public function Producer(){        //任务 消息内容. ---&gt;3000 小猪的详细信息 订单信息        $value = 'winner 的kafka';        //主题        $topic = 'order1';        $config = Kafka\ProducerConfig::getInstance();        $config-&gt;setMetadataRefreshIntervalMs(metadataRefreshIntervalMs:10000);        $config-&gt;setMetadataBrokerList(list:'localhost:9092');        $config-&gt;setBrokerVersion(version:'1.0.0');        //消息可靠        //当ack模式为1时，服务端的消息会持久化发送到主副本leader        //ack模式为0时，不会等待消息的持久化到主副本。        //ack模式为2时，        //可靠性:2&gt;1&gt;0        //性能:0&gt;1&gt;2        $config-&gt;setRequiredAck(requiredAck:'1');        //客户端生产消息的模式        //同步        //异步        //发后即忘        //性能：异步&gt;同步&gt;发后即忘        $config-&gt;setIsAsyn(asyn:false);        $config-&gt;setProduceInterval(produceInterval:500);        $producer = new Kafka\Prodecer(function() use($value,$topic){            return [                [                    'topic'=&gt;$topic,                    'value'=&gt;$value,                    'key =&gt; '',                ]            ];        });        dump($producer);        $producer-&gt;success(function($result){            dump($result);        });    }}消费者高级 如何保证消息可靠消费？  消息不能够被丢失，消息存在。 生产者：ACK机制使用默认值1 消费者：确认消费序列器 1次2次3次public function handle(){    $config = Kafka\ConsumerConfig::getInstance();    $config-&gt;setMetadataRefreshInstervalMs(metadataRefreshIntervalMs:500);    $config-&gt;setMetadataBrokerList(list:'localhost:9092');    //组    $config-&gt;setGroupId(groupId:'test1');    $config-&gt;setBrokerVersion(version:'1.0.0');    $config-&gt;setTopics(['order1']);    //$config-&gt;setOffsetReset('earliest);    $consumer = new Kafka\Consumer();    $consumer-&gt;start(function($topic,$part,$message){        var_dump($topic);        var_dump($part);        var_dump($message);    });}子副本消息数据库里的一行数据生产者发布消息的程序主题分区指定分区不指定分区键一个标记值消费者订阅消息的程序偏移量消费者根据偏移量读取数据broker1主题:圆蛋蛋分区0主题:圆蛋蛋分区1]]></content>
      <categories>
        
          <category> PHP </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Mac系统查看隐藏文件]]></title>
      <url>/mac/2021/09/12/mac-01/</url>
      <content type="text"><![CDATA[在mac系统下，默认看不到隐藏的目录，比如.git目录，通过下面的方法可以切换是否显示。使用快捷键Shift+Command+.同时按下Shift和Command和.三个键切换显示状态。使用命令行显示defaults write com.apple.finder AppleShowAllFiles TRUEkillall Finder隐藏defaults write com.apple.finder AppleShowAllFiles FALSEkillall Finder]]></content>
      <categories>
        
          <category> Mac </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[vscode 使用xdebug3.0.4调试]]></title>
      <url>/2021/07/10/vscode-xdebug/</url>
      <content type="text"><![CDATA[vscode 安装 PHP Debug 扩展左侧菜单栏扩展图标=&gt;搜索输入框=&gt;php debug=&gt;点击安装vscode 安装 PHP IntelliSense左侧菜单栏扩展图标=&gt;搜索输入框=&gt;PHP IntelliSense=&gt;点击安装php安装xdebug使用pecl工具来安装xdebug查找pecl工具的位置which pecl/usr/local/bin/pecl #pecl工具所在目录使用pecl工具安装xdebugpecl install xdebug创建zhaoqhu-php-ext-xdebug.inizend_extension=xdebug[xdebug]xdebug.mode = debug xdebug.start_with_request = yes xdebug.client_port = 9001 xdebug.client_host=192.168.100.226xdebug.idekey=VSCODEextension = php_screw_plus复制zhaoqhu-php-ext-xdebug.ini文件到php的配置文件目录下cp /var/www/html/zhaoqhu-php-ext-xdebug.ini /usr/local/etc/php/conf.d/检查zhaoqhu-php-ext-xdebug.ini文件的内容rm -f /usr/local/etc/php/conf.d/zhaoqhu-php-ext-xdebug.inicat /usr/local/etc/php/conf.d/zhaoqhu-php-ext-xdebug.inicat /var/www/html/zhaoqhu-php-ext-xdebug.inivscode 配置launch.json文件docker容器内的环境注意要添加pathMappings的配置，值为”server”:”local”{    "version": "0.2.0",    "configurations": [        {            "name": "Listen for Xdebug",            "type": "php",            "request": "launch",            "port": 9001,            "pathMappings": {                "/var/www/html":"/Users/zhaoqinghu/dev_docker/nextcloud/nextcloud"            }        },        {            "name": "Launch currently open script",            "type": "php",            "request": "launch",            "program": "${file}",            "cwd": "${fileDirname}",            "port": 9001        }    ]}调试execcat /sys/class/dmi/id/product_uuidcat /sys/class/dmi/id/board_serialcat /sys/class/dmi/id/board_namecat /sys/class/dmi/id/cat /sys/class/net/eth0/speedcat /sys/class/net/eth0/status		$product_uuid  = shell_exec('cat /sys/class/dmi/id/product_uuid');		$board_serial  = shell_exec('cat /sys/class/dmi/id/board_serial');		$board_name  = shell_exec('cat /sys/class/dmi/id/board_name');		$product_name  = shell_exec('cat sys/class/dmi/id/product_name');		$speed  = shell_exec('cat /sys/class/net/eth0/speed');make -p /home/dmi/ &amp;&amp; cp -rf /sys/class/dmi/id/ /home/dmi/ &amp;&amp; chmod -R 777 /home/dmi/]]></content>
      <categories>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Php7.4.16]]></title>
      <url>/2021/04/18/php7.4.16/</url>
      <content type="text"><![CDATA[apcubcmathCorectypecurldatedomexiffileinfofilterftpgdgmphashiconvimagickintljsonldaplibxmlmbstringmemcachedmysqlndopensslpcntlpcrePDOpdo_mysqlpdo_pgsqlpdo_sqlitePharposixreadlineredisReflectionsessionSimpleXMLsodiumSPLsqlite3standardtokenizerxmlxmlreaderxmlwriterZend OPcachezipzlib/usr/local/etc/php/conf.d/docker-php-ext-apcu.ini, /usr/local/etc/php/conf.d/docker-php-ext-bcmath.ini, /usr/local/etc/php/conf.d/docker-php-ext-exif.ini,  /usr/local/etc/php/conf.d/docker-php-ext-gd.ini,  /usr/local/etc/php/conf.d/docker-php-ext-gmp.ini,  /usr/local/etc/php/conf.d/docker-php-ext-imagick.ini,  /usr/local/etc/php/conf.d/docker-php-ext-intl.ini,  /usr/local/etc/php/conf.d/docker-php-ext-ldap.ini,  /usr/local/etc/php/conf.d/docker-php-ext-memcached.ini,  /usr/local/etc/php/conf.d/docker-php-ext-opcache.ini,  /usr/local/etc/php/conf.d/docker-php-ext-pcntl.ini,  /usr/local/etc/php/conf.d/docker-php-ext-pdo_mysql.ini,  /usr/local/etc/php/conf.d/docker-php-ext-pdo_pgsql.ini,  /usr/local/etc/php/conf.d/docker-php-ext-redis.ini,  /usr/local/etc/php/conf.d/docker-php-ext-sodium.ini,  /usr/local/etc/php/conf.d/docker-php-ext-zip.ini,  /usr/local/etc/php/conf.d/nextcloud.ini,  /usr/local/etc/php/conf.d/opcache-recommended.ini'./configure' '--build=x86_64-linux-gnu' '--with-config-file-path=/usr/local/etc/php' '--with-config-file-scan-dir=/usr/local/etc/php/conf.d' '--enable-option-checking=fatal' '--with-mhash' '--with-pic' '--enable-ftp' '--enable-mbstring' '--enable-mysqlnd' '--with-password-argon2' '--with-sodium=shared' '--with-pdo-sqlite=/usr' '--with-sqlite3=/usr' '--with-curl' '--with-libedit' '--with-openssl' '--with-zlib' '--with-pear' '--with-libdir=lib/x86_64-linux-gnu' '--with-apxs2' '--disable-cgi' 'build_alias=x86_64-linux-gnu''./configure' '--build=x86_64-linux-gnu' '--with-config-file-path=/usr/local/etc/php' '--with-config-file-scan-dir=/usr/local/etc/php/conf.d' '--enable-option-checking=fatal' '--with-mhash' '--with-pic' '--enable-ftp' '--enable-mbstring' '--enable-mysqlnd' '--with-password-argon2' '--with-sodium=shared' '--with-pdo-sqlite=/usr' '--with-sqlite3=/usr' '--with-curl' '--with-libedit' '--with-openssl' '--with-zlib' '--with-pear' '--with-libdir=lib/x86_64-linux-gnu' '--with-apxs2' '--disable-cgi' 'build_alias=x86_64-linux-gnu'./configure --prefix=/usr/local/php-7.2.9 \	--with-config-file-path=/usr/local/php-7.2.9/etc \	--with-mysql=mysqlnd \	--with-mysqli=mysqlnd \	--with-pdo-mysql=mysqlnd \	--enable-fpm \	--enable-fastcgi \	--enable-static \	--enable-inline-optimization \	--enable-sockets \	--enable-wddx \	--enable-zip \	--enable-calendar \	--enable-bcmath \	--enable-soap \	--with-zlib \	--with-iconv \	--with-gd \	--with-xmlrpc \	--enable-mbstring \	--without-sqlite \	--with-curl \	--enable-ftp \	--with-mcrypt  \	--with-freetype-dir \	--with-jpeg-dir \	--with-png-dir \	--disable-ipv6 \	--disable-debug \	--with-openssl \	--disable-maintainer-zts \	--disable-safe-mode \	--disable-fileinfo]]></content>
      <categories>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Mac系统下设置全局默认的php版本和Mysql的版本]]></title>
      <url>/php/2021/04/18/mac-default-php-mysql/</url>
      <content type="text"><![CDATA[Mac系统下设置全局默认的php版本Mac系统版本Mac OS big Sur，这个版本的系统默认装的php版本是php7.3.24 ,可能你还会在自己的电脑上安装其他的php版本，比如php5,php7.1.5,,php7.4.16。如果电脑上面装了多个版本的php，可以指定某一个版本的php为全局默认的，假如我们设定全局默认的php版本是php7.1.5找到php7.1.5版本bin目录下的二进制可执行的php文件所在目录的路径为/usr/local/php7-15/bin/php找到 ~/.zshrccd ~/ls -al #列出目录下面所有文件修改 ~/.zshrc使用超级管理员的权限命令打开.zshrc文件sudo vim ~/.zshrc将下面的设定php全局变量的命令粘贴到.zshrc文件中export PATH="/usr/local/php7-15/bin:$PATH"重新载入 ~/.zshrc文件执行下面的命令重新载入.zshrc文件，使添加的php全局变量执行文件生效。source ~/.zshrcMySQL设置指定版本为全局变量指定方法可以参考设定PHP指定版本为全局变量的方法。]]></content>
      <categories>
        
          <category> PHP </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[nextcloud yml安装]]></title>
      <url>/nextcloud/2021/03/09/nextcloud-yml/</url>
      <content type="text"><![CDATA[创建nextcloud安装目录mkdir nextcloud创建mysql目录用于数据卷映射cd ~/nextcloudmkdir mysql创建nextcloud文件目录用于映射cd nextcloudmkdir nextcloud创建docker-compose.yml文件，内容如下version: '2'volumes:  nextcloud:  db:services:  db:    image: mysql    restart: always    command: --default-authentication-plugin=mysql_native_password    volumes:      - /Users/zhaoqinghu/dev_docker/nextcloud/mysql:/var/lib/mysql    environment:      - MYSQL_ROOT_PASSWORD=12345678      - MYSQL_PASSWORD=nextcloud      - MYSQL_DATABASE=nextcloud      - MYSQL_USER=nextcloud  app:    image: nextcloud    restart: always    ports:      - 7080:80    links:      - db    volumes:      - /Users/zhaoqinghu/dev_docker/nextcloud/nextcloud:/var/www/html    environment:      - MYSQL_PASSWORD=      - MYSQL_DATABASE=nextcloud      - MYSQL_USER=nextcloud      - MYSQL_HOST=db]]></content>
      <categories>
        
          <category> nextcloud </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[php面试]]></title>
      <url>/php/2021/02/05/php-ms/</url>
      <content type="text"><![CDATA[线程和进程的区别简而言之,一个程序至少有一个进程,一个进程至少有一个线程php-fpm是一个主进程master和多个工作进程worker，每个php-fpm进程有一个线程。1、php的哪些语言特性，在合适的场景可以显著减少内存开销？spltraitGeneratortype hint2、对于php的自动加载描述正确的是？Composer的自动加载是通过__autoload函数实现在文件顶部use的时候会载入对应的类自动加载函数只支持按Class/Interface/Trait名加载，不能按function名加载现在大多数类库都遵循psr0规范3、对于Trait描述正确的是可以用来减少重复代码一个类无法同时引入两个包含相同方法的Trait子类中引入的Trait利的方法会覆盖父类的方法在Trait中不可以调用引用类里的方法4、下列对Composer描述正确的是拿到一个Project类型的项目时，需要通过composer update来安装对应的依赖包一般情况下应该把PHPUnit包含在require段composer.json不仅可以指定依赖的PHP类库，还能指定依赖的PHP扩展Library类型的项目，需要把composer.lock文件提交到版本库中5、如果一个包遵循Semantic Version，下列哪些版本升级大概率不会出问题6、按照RESTFul的规范，修改文章的展示隐藏应该使用哪一种路由7、通常使用过滤特殊字符的方式来避免SQL注入8、只要项目中使用了PDO的prepare就能完全避免SQL注入9、CSRF攻击是因为没有对用户输入进行转义导致的14、为了避免XSS攻击，需要在写入数据库前对其转义，从数据库读取后反转义]]></content>
      <categories>
        
          <category> PHP </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Elasticsearch 学习]]></title>
      <url>/2021/02/04/Elesticsearch/</url>
      <content type="text"><![CDATA[]]></content>
      <categories>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[php高级教程-大型电商平台双十一Redis高并发秒杀解决方案]]></title>
      <url>/php/2021/01/28/php-redis-seckill/</url>
      <content type="text"><![CDATA[使用场景介绍秒杀红包1、时间短、数量少2、大流量、高并发数据安全1、业务场景、高并发会引发问题2、压力测试工具的使用3、悲观锁、乐观锁、lua脚本4、不同场景的解决方案2.2redis一些相关的原理（10服用、原子性）秒杀场景遇到的问题1、卡顿崩溃2、超卖（库存变为负数）模拟秒杀库存只有3件的商品，如果用压力测试工具进行模拟500人进行秒杀的情况，比如发送了5000次链接，如果不做处理一定会出现商品超卖的情况，实际成功的订单会大于3个，商品库存会变成负数，比如-36，那实际上成功的订单会是39个订单，超卖了36件，这样子就赔钱了。使用压力测试工具模拟高并发场景ab -n 请求数 -c 并发数 url地址ab -n 500 -c 5000 http://127.0.0.1/seckill/buy.php #模拟500个客户端发送5000个请求解决办法数据库悲观锁redis1、redis速度快（单机的读写速度可以达到8万左右）2、数据限制悲观锁：假设当前的数据操作一定会发生冲突的，屏蔽一切（行锁、文件锁）如果用mysql的行锁会导致阻塞、等待状态，会崩溃。性能差，速度慢。乐观锁：假设当前的数据不会发生并发冲突，在真写数据的时候，再去检查，有没有发生冲突。苹果商店排行20的App淘宝客双十一销售额，5亿，每秒并发14w]]></content>
      <categories>
        
          <category> PHP </category>
        
      </categories>
      <tags>
        
          <tag> PHP </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Redis nginx memcached]]></title>
      <url>/redis/nginx/memcached/2021/01/25/Redis-nginx-memchached/</url>
      <content type="text"><![CDATA[]]></content>
      <categories>
        
          <category> Redis </category>
        
          <category> nginx </category>
        
          <category> memcached </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Redis 学习]]></title>
      <url>/nosql/redis/2021/01/23/redis-learning/</url>
      <content type="text"><![CDATA[版本当前最新版本是6.0redis安装下载最新的稳定版，makemake PREFIX=/usr/local/redis installcd /usr/local/redis/bin #进入redis安装后的binary目录ls #查看目录下的命令行工具redis-benhmark  #redis性能测试工具redis-check-aof #检查aof日志的工具redis-check-dump #检查rdb日志的工具redis-cli #链接用的客户端工具redis-server #redis服务进程启动复制redis源码中的配置文件cd /usr/local/rediscp /usr/local/src/redis-2.6.16/redis.conf ./启动redis服务/usr/local/redis/bin/redis-server ./redis.onfredis后台运行服务修改redis.conf中的daemonize改为yes五大ValueString字符串类型的操作set key value [ex 秒数][px 毫秒数]如果 ex 秒数和px 毫秒数，同时使用，则以后面的为准flushdb #清空数据set site www.zixue.itttl site #查看生命周期,默认的生命周期是永久set search www.baidu.com ex 10 px 6567pttl searchflush dbflushdb #清空数据set site www.so.comset site www.baidu.com nx# nx的参数表示如果没有这个key才可以执行get site #返回结果依然是www.so.comset site www.google.com xx #xx的参数表示如果有这个key才可以执行get site #返回值是www.google.comset abc www.google.com xx#xx表示有这个key才可以执行mset a aman b bold c controller d diamondkeys #返回a、b、c、dmget a b c#一次获取多个keyflushdbset word helloget wordsetrange word 2 ??get word #返回结果he??oset word hello setrange word 6 !get world #返回结果hello\x00!append word @@#getrange key start stopset area chinesegetrange area 1 4 字符串数值二进制help @StringList链表lpush charlist arpush charlist brpush charlist blpush charlist 0lrange charlist 1 2lrange charlist 1 3lrange charlist 0 3lrange charlist 0 -1 #查看所有的链表上的值lpop charlist #弹出最左边的值，链表上的值会消失rpop charlist #弹出最右边的值，链表上的值会消失flushdb #清空所有rpush answer a b c a b d alrem answer 1 b#删除链表answer上的一个blrem answer -2 a#从链表answer最后开始删除两个afushdbrpush charlist a b c d e flrange charlist 0 -1ltrim charlist 2 5lindex charlist  0lindex charlist 1lindex charlist 2llen charlist #查看链表的长度lrpush num 1 3 6 8 9 #创建一个num链表linsert num before 3 2 #在链表num值3的前面添加2linsert num after 9 10lrange num 0 -1linsert num after 99 10linsert num after 9 10flushdbrpush task a b c drpoplpush task job #右边弹出task链表的值d存储到链表d左边rpop job brpop job 20 #等待20秒,当收到新值后结束lpush job eblop job位图法统计活跃用户3天连续登录setbit mon 1000000000 0setbit mon 3 1setbit mon 5 1setbit mon 7 1set tues 100000000 0Hashhset user1 name lisihset user1 age 28hset user1 height 175hgetall user1hmset user2 name wang age 10 height 100hgetall user2hget user1 name hget user2 namehmget user1 name heighthgetall user1hdel user1 agehgetall user1hlen uesr1hlen user2hexists user1 agehexists user2 agehincrby user2 age 1hgetall user2hget user2 agehincrbyfloat user2 age 0.5hkeys user2hvals user2Set1、无序性 2、确定性 3、唯一性sadd gender male femalesadd gender yao yaosadd gender yaosmembers gender #查看gender所有的值srem gender yao #删除yaosrem gender x c #删除失败(integer 0)srem gender male x c #成功删除(male)spop key #随机删除sadd gender a b c d e f spop gender #随机删除无序集合gender里的值smembers gendersrandmember gendersismember gender Q #判断某个vlue在某个集合中sismember gender fscard gender #返回集合中元素的个数sadd uuper A B Csadd lower a b csmove upper lower A #移动upper集合中的A到集合lower中smembers uppersmembers lowersadd lisi a b c dsadd wang a b c d e fsadd poly a b c d gsinter lisi wang poly #求交集sunion lisi wang poly#求并集sdiff lisi wangsinter lisi wang polysintersrore result lisi wang poly #求并集存入到resultZSetorder set 有序集合flushdbzadd class 12 lily 13 lucy 18 lilei 6 polyzrange class 0 3#有序的查询出class集合中的前四个人zrangebyscore class 13 18 #查询13岁到18岁的人zrangebyscore class 1 20 limit 1 2zrange class 1 3 withscoreszrangebyscore class 10 20 withscores #查看分数去某个范围内元素。zrange class 0 -1zrank class lilyzrank class polyzrank class lileizrank class zhangfeizrevrank class lileizrange class 0 -1 withscoreszremrangebysore class 10 15zrange class 0 -1 withscoreszadd class 12 lily 13 lucyzremrangebyrank class 0 1#删除poly 和lilyzrange class 0 -1 withscoreszrem class lucyzrange class 0 -1 withscoreszrem class lileizrane class 0 -1 withscoreszadd ty 25 zhangfei 27 guanyu 28 libeizcard ty zadd ty 23 zhaoyunzcard tyzcoun ty 25 30flushdbzadd lisi 3 cat 5 dog 6 horsezadd wang 5 cat 6 dog 8 horse 1 donckeyzinterstore result 2 lisi wangzrange result 0 -1 zinterstore result 2 lisi wang aggregate minzrange result 0 -1zinterstore result 2 lisi wang aggregate maxzinterstore result 2 lisi wang weight 2 1 aggreagate maxzrange result 0 -1 withscoreszinterstore result 2 lisi wang weights 2 1 aggregate sum zrange result 0 -1 withscoresredis 事务redis开启事务后，所有的执行语句先放入到队列中，如果想取消可以执行discard命令，但是如果执行exec后，在队列中的语句已经执行成功了，回滚不回来，不支持回滚fulshdbset wang 200set zhao 700multi #开启事务decrby zhao 100incryby wang 100exec #执行成功multi #开启事务decryby zhao 100sdfaexec 执行错误mget zhao wangmulti #开启事务decryby zhao 100sadd wang pigexec #执行错误multi #开启事务decrby zhao 100incrby wang 100discard #取消 #买票场景当车票只剩一张时，李四正在买票，redis开启事务，已经把修改车票和修改用户钱数的语句放到队列，还未执行exec，正在此时，王五把这张票买走了。flushdbset ticket 1set lisi 300set wang 300#李四买票multidecr ticketdecrby lisi 100#exec尚未执行exec#王五买票成功了。decr ticketget ticket#李四开启watch买票set ticket 1watch ticketmultidecr ticketdecrby lisi 100#exec尚未执行，这时王五又执行了desc ticketget ticketwatch key1 key2 key3#监听多个keyunwatch #取消监听多个key频道发布与消息订阅服务端publish news "today is sunshine"publish news "still sunshine"publish news "away sunshine"publish news "thress"publish newstop "four"客户端1subscribe news客户端2subscribe newspsubscribe new*redis和memcached相比的独特之处1、redis可以用来做存储(storage)，而memcached是用来做缓存(cache)，这个特点主要因为其有持久化的功能2、存储的数据有“结构”，对于memcached来说，存储的数据，只有1种类型“字符串”，而redis则可以存储字符串、链表、哈希结构、集合、有序集合]]></content>
      <categories>
        
          <category> NoSql </category>
        
          <category> Redis </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Laravel 安装]]></title>
      <url>/php/laravel/2021/01/23/laravel-install/</url>
      <content type="text"><![CDATA[Composer全量镜像配置由于国内用户访问Composer镜像的官方网站，在使用php的包管理工具Composer安装时，可能会下载安装的很慢，或者下载安装失败。推荐使用国内阿里云镜像composer config -g repo.packagist composer https://mirrors.aliyun.com/composer/ #全局安装composer config -g --unset repos.packagist #取消配置composer config repo.packagist composer https://mirrors.aliyun.com/composer/ #单个项目局部配置composer config --unset repos.packagist #单个项目局部取消配置安装最新版本laravelcd /Users/zhaoqhu/www/mkdir laravel_last #创建文件夹composer create-project   laravel/laravel  ./  #安装laravel最新版本的框架到当前目录php artisan #查看laravel框架的版本，目前的最新版本是8.24.0安装指定版本laravelcd /Users/zhaoqhu/www/mkdir laravel_7_30_4composer create-project   laravel/laravel ./   "7.30.*";php artisan Github下载laravel指定版本压缩包解压安装访问Github上对应的版本https://github.com/laravel/laravel/archive/v7.30.0.zip,然后下载到本地电脑，然后解压，然后进入7.30.0目录unzip v7.30.0 cd laravel-7.30.0composer install #安装php artisan -V #查看版本使用 laravel命令行工具安装查看composer的home所在的目录，通过下面的命令，然后找到[home] /Users/zhaoqhu/.composercomposer global require laravel/installer #安装laravel命令行工具composer config -l #查看composer配置cd ~/.composer/vendor/bin#查看laravel命令行工具是否存在 ~/.composer/vendor/bin/laravel new example-app; #安装参考教程  larave Composer安装方式   阿里云 Composer 全量镜像  中国全量镜像]]></content>
      <categories>
        
          <category> PHP </category>
        
          <category> Laravel </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[使用docker-compose.yml创建lnmp环境]]></title>
      <url>/docker/2021/01/23/docker-compose-npm-yml/</url>
      <content type="text"><![CDATA[创建docker-compose.yml文件version: "3"services:  nginx:    image: nginx:alpine    ports:    - 80:80    volumes:    - ./html:/usr/share/nginx/html    - ./nginx/nginx.conf:/etc/nginx/nginx.conf  php:    image: devilbox/php-fpm:8.0-work-release-0.123    volumes:    - ./html:/var/www/html  mysql:    image: mysql:5.6    environment:    - MYSQL_ROOT_PASSWORD=123456启动docker-compose up -d参考资料https://github.com/bobo132/docker-compose-demo-1]]></content>
      <categories>
        
          <category> Docker </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Docker 学习]]></title>
      <url>/2021/01/21/docker-learn/</url>
      <content type="text"><![CDATA[Docker公司简介地址：美国剑桥大街318号加州帕洛阿尔托94306Docker工具简介:Docker是开源应用容器的应用容器引擎，基于Go语言开发实现，属于操作系统层面的虚拟化技术。Docker可以让开发者打包他们的应用以及依赖包到一个轻量级，可移植的容器中，然后发布到任何有Docker的电脑(window和Linux)上。容器是完全使用沙箱机制，相互之间不会有任何接口（类似iphone的app）,更重要的是容器性能开销极低。Docker能做什么Docker 可以解决虚拟机能够虚拟机解决的问题，同时能够解决虚拟机由于电脑资源过高而无法解决的问题。Docker在线工具https://labs.play-with-docker.com/Docker中每个镜像都拥有一个Linux发行版系统，拥有完整的运行环境Docker的主要用法也是创建多个镜像，通过应用编排构成一个完整的应用镜像越多，在同一台服务器中就会有越多的运行环境（发行版系统），它们本身也会造成开销请问在这种多镜像的环境下，Docker是否会因为系统过多，造成极大的额外开销？Docker安装docker远程仓库镜像Image容器ContainerDocker命令docker infodocker versiondocker run hello-worlddocker镜像加速“registry-mirrors”: [    “https://jtjwzjlb.mirror.aliyuncs.com”,    “https://registry.docker-cn.com”  ]下载镜像：从Docker远程镜像仓库获取镜像的命令是docker pull。请命令格式为：docker pull 镜像名字下载技巧从 https://hub.docker.com/上面搜索镜像的安装方式，但是实际上是从阿里云加速镜像上面下载的。例如：docker pull training/webappdocker pull busyboxdocker pull centostraining/webapp #python的appbusybox:是一个集成了三百多个最常用Linux命令工具，简化的Linux系统centos：linux系统容器查看镜像docker image ls或者docker images删除镜像            docker image rm 镜像名字      镜像id      通过镜像创建容器进行容器操作查看正在运行的容器docker ps查看所有容器docker ps -a启动容器基于镜像新建一个容器并启动，启动一个已存在的容器docker run training/webapp提示启动了一个服务，http://0.0.0.0:5000/端口映射            docker run -p 本地端口:容器端口 容器名字      容器id      后台运行语法docker -d run -p 8888:5000 training/webapp在本地电脑浏览器中执行localhost:8888，就可以看到hello world交互运行启动一个bash终端，允许用户进行交互。            docker run -t -i 容器名字      容器id /bin/bash      -t选项让docker分配一个伪终端(pseudo-tty)并绑定到容器的标准输入上。-i则让容器的标准输入保持打开。在交互式模式下，用户可以通过所创建的终端来输入linux命令.例如docker run -it centos /bin/bash创建centos 容器并且进入centos容器中退出容器exit终止容器docker stop 容器id删除容器docker rm 容器id开启容器docker start 容器id重启容器docker restart 容器id查看容器启动产生的数据。docker logs 容器的id进入正在运行的容器里主机和容器之间拷贝文件容器拷贝到主机docker cp 容器id:/opt/webapp/app.py d:/www主机拷贝到容器docker cp d:/www/文件 容器id:/opt/webapp/8、数据卷什么是数据卷数据卷是一个可供一个或多个容器使用的特殊目录，他绕过UFS，可以提供很多有用的特性：1、数据卷可以在容器之间共享和重用2、对数据卷的修改会立马生效3、对数据卷的更新，不会影响镜像4、数据卷默认会一直存在，即使容器被删除使用docker run -d -p 8888:5000 -v d:/wwww/webapp:/opt/webapp 31ff6ac986e0(容器id)***前提需要检查docker配置项中的FILE SHARING中是否包含想要创建的数据卷目录。Docker应用-搭建PHP开发环境9.1下载阿里云的lamp镜像docker pull registry.cn-hangzhou.aliyuncs.com/itsource/centos-lamp:v3docker run -itd  -p 80:80 -p 3306:3306 –name lamp –privileged=true -v /data/wwwroot/www.baidu.com:/data/wwwroot/www.baidu.com  registry.cn-hangzhou.aliyuncs.com/itsource/centos-lamp:v2  /usr/sbin/init-i 选项让Docker分配一个伪终端（pseudo-tty）并绑定到容器的标准输入上-t 则让容器的标准输入保持打开。-d 则让容器在后台运行。–name lamp为容器起名为lamp–privileged=true 让container内的root拥有真正的root权限。-v 创建数据卷，将本地主机目录挂着到容器的指定目录中/usr/sbin/init是为了获取root权限制作阿里云镜像  #### 将修改后的容器生成镜像 docker commit -a “itsource” -m “this is my centos” 3ee458166862(容器id) my-centos:v2 *** -a 作者的名字 -m注释都要使用双引号登录到阿里云界面=&gt;镜像列表=&gt;创建镜像仓库地址：华东1命名空间：itsource仓库名称：my-centos2摘要：my-centos2描述信息：my-centos2仓库类型：公开设置代码源：本地仓库根据创建的镜像仓库zhaoqhu_docker_image根据操作指南把本地仓库推送到阿里云上面。]]></content>
      <categories>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[php xdebug安装和调试]]></title>
      <url>/php/2021/01/20/php-xdebug/</url>
      <content type="text"><![CDATA[php安装xdebug先查看php版本，然后在确定下载xdebug的版本。比如php的版本是7.1.5，访问xdebug历史版本下载页https://xdebug.org/download/historical，然后选定并下载和php版本匹配的Linux,macOS Source，Xdebug2.5.5这个版本支持php7.1.5,下载地址是https://xdebug.org/files/xdebug-2.5.5.tgz。使用php7.1.5自带的工具phpize工具进行编译安装比如php7.1.5安装的目录是/usr/local/php7-15，phpize工具所在的目录是/usr/local/php7-15/bin/phpizexdebug-2.5.5.tgz解压tar -zxvf xdebug-2.5.5.tgz -C /usr/local/php7-15-modules/cd xdebug-2.5.5/usr/local/php7-15/bin/phpize #执行生成configure文件./configure   --with-php-config=/usr/local/php7-15/bin/php-configmakemake install配置php.ini查看php.ini文件位置/usr/local/php7-15/bin/php --ini打开并修改;xdebug startzend_extension="/usr/local/php7-15/lib/php/extensions/no-debug-non-zts-20160303/xdebug.so"xdebug.remote_enable = on #*xdebug.remote_autostart = on #*xdebug.remote_handler = dbgpxdebug.remote_host = 127.0.0.1xdebug.remote_port=9001;xdebug endsublime text3安装xdebug界面打开首选项=&gt;Package Control=&gt;Install Package快捷键打开打开命令行输入Mac上输入快捷键Command+shift+p，Windows上快捷键Control+shift+pPackage Control: Install Packagexdebug-client配置sublime text3首选项=&gt;Package Settings=&gt;Package Control=&gt;Xdebug=&gt;Settings-User{"port": 9001,}Chrome 安装Xdebug helper 插件安装方法配置Xdebug helperIDE key，选其他，输入sublime.xdebugFirefox安装Xdebug helper插件安装方法打开附加组件=》搜索Xdebug helper=&gt;安装配置IDE key，选其他，输入sublime.xdebug检查是否配置成功创建index.php&lt;?phpvar_dump("hello xdebug"); #设置断点?&gt;开启调试快捷键打开命令行输入工具Command+shif+p,输入:Xdebug: Start Debugging浏览器访问 localhost/index.php检查Xdebug Context控制台如果控制台有内容输出，证明配置成功$_COOKIE = array[1]$_COOKIE['XDEBUG_SESSION'] = (string) sublime.xdebug$_ENV = array[0]$_FILES = array[0]$_GET = array[0]$_POST = array[0]$_REQUEST = array[0]vscode编写php项目php intellisense扩展php debug扩展"php.suggest.basic": false,"php.validate.executablePath": "/usr/local/php7-15/bin"]]></content>
      <categories>
        
          <category> PHP </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[php-fpm优化]]></title>
      <url>/php/2021/01/16/php-fpm-optimize/</url>
      <content type="text"><![CDATA[php-fpm进程管理器进程和线程一个进程对应一个线程查看php-fpm进程所占用的内存ps aux | grep php-fpm|awk ‘{mem+=$6}END {print mem}’通过上面的命令可以计算出php-fpm总共使用的内存，例如有一个主php-fpm进程，2个子php-fpm进程，总共使用的内存为45460，平均每个php-fpm进程使用的内存是15兆。在实际使用过程中每个php-fpm进程使用的内存是20兆。五、进程管理器的核心优化1.动态创建子进程pm = dynamic2.最大子进程数:pm.max_children = 100(默认5)#每开启一个php-fpm进程要占用20M左右的内存，假设服务器内存为2G，优化的目的是让php-fpm达到服务器内存的顶配3.初始进程数：pm.start_servers = 40(默认2)4.最小空闲进程数:pm.min_spare_servers = 20(默认1)5.最大空闲进程数:pm.max_spare_servers = 60（默认3）6.最大多少次请求后子进程重生：pm.max_requests = 10240#有效降低内存消耗php5.3.3以后的php-fpm不在支持php-fpm以前具有的/usr/local/php/sbin/php-fpm(start|stop|reload)等命令，所以不要在看这种老掉牙的命令了，需要使用信号控制：master进程可以理解一下信号INT,TERM立刻终止QUIT平滑终止USR1重新打开日志文件USR2平滑重载所有worker进程并重新载入配置额二进制模块六、进程状态监控：1、php配置：pm.status_path = /phpstatus2.nginx设置方法：location /phpstatus {	fastcgi_index index.php;	fastcgi_pass 127.0.0.1:9000;	fastcgi_param SCRIPT_FIFILENAME $document_root$fastcgi_script_name;	include		fastcgi_params;}3.客户端测试：http://192.168.2.1/phpstatus4.进程状态信息：pool: www								#进程池名称process manager: dynamic					#进程池管理方式start time; 22/Jan/2016:15:49:00 +0800		#启动时间start_since: 375							#运行时长accepted conn: 7							#当前进程池接受的请求数listen queue: 0							#请求等待队列，如果不为0，意味着FPM进程不足，需要增加max listen queue: 0						#最大等待数量确定是否换硬件listen_queue_len:1024						#SOCKET等待队列长度ide_processes:							#空闲进程数active_processes:							#活跃进程数total_processes:							#总进程数max active_process: 1						#最大活跃进程数，确定是否换硬件max_children reached: 0					#达到最大进程数的次数，如果不为0，意味着最大进程数不足，需要增加，确定是否换硬件 slow requests: 							#慢请求数量，需要设置 slow log七、生成访问日志：access.log = log/$pool.access.logaccess.format = “%R - %u %t \”%m %r%Q%q\” %s %f %{mili}d %{kilo}M %C%% ”八、开启慢日志request_slowlog_timeout = 5slowlog = log/$pool.log.slow九、增加php-fpm打开文件数的限制rlimit_files = 65535十、每个php-fpm进程的内存限制(php.ini)memory_limit = 128M十一、进程最大执行时间，与php.ini中max_execution_time作用相同(php.ini)max_execution_time=30phpstatus/usr/local/php/sbin/php-fpm -t #测试配置文件是否正确十二、ab压力测试#ab-&gt;nginx-&gt;php-&gt;index.phpApacheBench压力测试ab -n10 -c10ab -n1000 -c1000ab -n10000 -c10000ab -n18000 -c18000]]></content>
      <categories>
        
          <category> PHP </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[mysql 分区学习]]></title>
      <url>/mysql/2021/01/14/mysql-partition/</url>
      <content type="text"><![CDATA[MySQL的分区-1什么是分区所谓分区就是将一个表分解成多个区块进行操作和保存，从而降低每次操作的数据，提高性能。而对应用来说是透明的，从逻辑上看是只有一个表（这里跟分库分表的访问不一样），但在物理上这个表可能是有多个物理分区组成的，每个分区都是一个独立的对象，可以进行独立处理。分区能干什么1：进行逻辑数据分割，分割数据能够有多个不同的物理文件路径 2：可以存储更多的数据，突破系统单个文件最大的限制 3：提升性能，提高每个分区的读写速度，提高分区范围查询的速度 4：可以通过删除相关分区来快速删除数据 5：通过跨多个磁盘来分散数据查询，从而提高磁盘I/O的性能 6：涉及到例如SUM()和COUNT()这样聚合函数的查询，可以很容易地进行并行处理 7：可以备份和恢复独立的分区，这对大数据量很有好处 ## 分区能支持的引擎 MySQL支持大部分的存储引擎创建分区,如MyISAM、InnoDB等；不支持MERGE和CSV等来创建分区。同一个分区表中的所有分区必须是同一个存储引擎。MySQL的分区-2从MySQL5.1开始引入分区功能，可以如下方式查看是否支持1:“老”的版本用: SHOW VARIABLES LIKE ‘%partition%’;2:新的版本用: show plugins;分区类型1：RANGE分区：基于属于一个给定连续区间的列值，把多行分配给分区（最常用的分区）2：LIST分区：类似于按RANGE分区，LIST是列值匹配一个离散值集合中的某个值来进行选择3：HASH分区：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算，这个函数必须产生非负整数值。 4：KEY分区：类似于按HASH分区，由MySQL服务器提供自身的哈希函数但是不论什么类型的分区，都要注意一下问题：1、如果表中存在primary key 或者unique key的一个组成部分，也就是说，分区函数的列只能从pk或者uk这些key中取子集2、如果表中不存在任何的primary key 或者unique key，则可以指定任何一个列作为分区列3、5.5版本的Range、List、Hash分区要求分区键必须是int，MySQL5.5及以上，支持非整形的Range和List分区，即：range columns和 list columns。#MySQL的分区-3分区命名分区的名字基本上遵循其他MySQL标识符应当遵循的原则，例如用于表和数据库命字的标识符。但是应当注意，分区的名字是不区分大小写的。无论使用何种类型的分区，分区总是在创建时就自动的顺序编号，且从0开始记录。创建分区1:Range分区CREATE TABLE tbl_users(	uuid INT NOT NULL,	customerId VARCHAR(20),	pwd VARCHAR(20),	showName VARCHAR(100),	trueName VARCHAR(100),	registerTime VARCHAR(100))PARTITION BY RANGE(uuid) (	PARTITION p0 VALUES LESS THAN (5),	PARTITION p1 VALUES LESS THAN (10),	PARTITION p2 VALUES LESS THAN (15),	PARTITION p3 VALUES LESS THAN MAXVALUE)insert into tbl_users value(1,'id1','a','s1','t1','');insert into tbl_users value(8,'id8','a','s8','t8','');insert into tbl_users value(20,'id20','a','s20','t20','');1-2、RANGE columns固定值格式的字段比如时间CREATE TABLE tbl_users3(	uuid INT NOT NULL,	customerId VARCHAR(20),	pwd VARCHAR(20),	showName VARCHAR(100),	trueName VARCHAR(100),	registerTime VARCHAR(100))PARTITION BY RANGE columns(customerId) (	PARTITION p0 VALUES LESS THAN ('id05'),	PARTITION p1 VALUES LESS THAN ('id10'),	PARTITION p2 VALUES LESS THAN ('id15'))insert into tbl_users value(1,'id1','a','s1','t1','');insert into tbl_users value(8,'id8','a','s8','t8','');insert into tbl_users value(20,'id20','a','s20','t20','');#MySQL的分区-41)到存放数据的地方查看文件，路径配置在/usr/bin/mysql_config里面的ldata。$ nano mysql_configldata=’/var/lib/mysql’$ cd /var/lib/mysql$ cd arch1$ lstbl_users#p0.ibdtbl_users#p1.ibdtbl_users#p2.ibdtbl_users#p3.ibd2)可以通过使用形如：SELECT * FROM information_schema.partitions WHERE table_schema=’arch1’ and table_name = ‘tbl_users’ \G 的语句来查看分区信息3）可以通过形如select * from tbl_users partition(p0)的语句来查看分区上的数据4)可以使用形如EXPLAIN partitions select * from tbl_users where uuid = 80来查看分区2：List分区按类型分区CREATE TABLE tbl_user2(	uuid INT NOT NULL,	customerId VARCHAR(20),	pwd VARCHAR(20),	showName VARCHAR(100),	trueName VARCHAR(100),	registerTime VARCHAR(100))PARTITION BY LIST(uuid){	PARTITION p0 VALUES in(1,2,3,5)	PARTITION p0 VALUES in(7,9,10)	PARTITION p0 VALUES in(11,15)}1）如果试图操作的列值不在分区值列表中时，那么会失败并报错。要注意的是，LIST分区没有类似如“VALUES LESS THAN MAXVALUE”这样的包含其他值在内的定义，将要匹配的任何值都必须在值列表中找到。2）LIST分区除了能和RANGE分区结合起来生成一个复合的子分区，与HASH和KEY分区结合起来生成复合的子分区也是可以的。3：Hash分区HASH分区主要用来确保数据在预先确定数目的分区中平均分布。在RANGE和LIST分区中，必须明确指定一个给定的列值或列值集合以指定应该保存在哪个分区中：而在HASH分区中，MySQL自动完成这些工作，要做的只是基于将要被哈希的列值指定一个表达式，以及指定被分区的表将要被分割成的分区数量，如：应用场景：运动员参赛时，年龄会在固定的区间CREATE TABLE tbl_users4(	uuid INT NOT NULL,	customerId VARCHAR(20),	pwd VARCHAR(20),	showName VARCHAR(100),	trueName VARCHAR(100),	registerTime VARCHAR(100))PARTITION BY hash(uuid)Partitions 3insert into tbl_users value(1,'id1','a','s1','t1','');insert into tbl_users value(8,'id8','a','s8','t8','');insert into tbl_users value(20,'id20','a','s20','t20','');默认是按uuid 除3取余数1）由于每次插入、更新、删除一行，这个表达式都要计算一次：这意味着非常复杂的表达式可能会引起性能问题，尤其是在执行同时影响大量行的运算（例如批量插入）的时候。2）最有效率的哈希函数是只对单个表列进行计算，并且它的值进行一致地增大或减小，因为这考虑了在分区范围上的“修剪”。也就是说，表达式值和她所基于的列的值变化越接近，就能越有效地使用该表达式来进行HASH分区。3.1： 线性Hash4：Key分区CREATE TABLE tbl_users4(	uuid INT NOT NULL,	customerId VARCHAR(20),	pwd VARCHAR(20),	showName VARCHAR(100),	trueName VARCHAR(100),	registerTime VARCHAR(100))PARTITION BY linear key(uuid)Partitions 3insert into tbl_users value(1,'id1','a','s1','t1','');insert into tbl_users value(8,'id8','a','s8','t8','');insert into tbl_users value(20,'id20','a','s20','t20','');5: 子分区子分区是分区表中每个分区的再次分割，适合保存非常大量的数据。MySQL的分区-12其他1：最大分区数目不能超过1024，一般建议对单标的分区数不要超过150个2：如果含有唯一索引或者主键，则分区列必须包含在所有的唯一索引或者主键在内3：不支持外检4：不支持全文索引，对分区表的分区键创建索引，那么这个索引页将被分区5：按日期进行分区很合适，因为很多日期函数可以用。但是对于字符串来说合适的分析函数不太多6：只有RANGE和LIST分区能进行子分区，HASH和KEY分区不能进行子分区7：临时表不能被分区8：分区表对于单条记录的查询没有优势9：要注意选择分区的成本，每插入一行数据都需要按照表达式筛选插入的分区10：分区字段尽量不要可以为null分库分表-1为什么要分库分表先考虑分区，然后考虑分库分表。数据库的复制能解决访问问题，并不能解决大规模的并发写入问题，由于无法进行分布式部署，而一台服务器的资源（CPU、磁盘、内存、IO等）是有限的，最终数据库所能承载的数据量、数据处理能力都将遭遇瓶颈。要解决这个问题就要考虑对数据库进行分库分表了，它有如下好处：1、解决磁盘系统最大文件限制，比如常见的有：FAT16(最大分区2GB，最大文件2GB)FAT32(最大分区32GB，最大容量2TB，最大文件32GB)NTFS（最大分区2TB，最大容量，最大文件2TB）EXT3(最大文件大小：2TB，最大文件极限：仅受文件系统大小限制，最大分区/文件系统大小：4TB，最大文件名长度：255字符)2、减少增量数据写入时的锁对查询的影响，减少长时间查询造成的表锁，影响写入操作等竞争的情况，节省排队的时间开支，增加吞吐量。3、由于表单数据量下降，常见的查询操作由于减少了需要扫描的记录，使得单标单次查询所需要的检索行数变少，减少了磁盘IO，时延变短。MySQL单表500万到1000 万]]></content>
      <categories>
        
          <category> MySQL </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Vue CLI学习笔记]]></title>
      <url>/vue/2019/12/09/vue-cli-learning/</url>
      <content type="text"><![CDATA[Vue CLI、Vue GUI、vue-cli-service、vue-router、vue-loaderVue CLI安装  Node 版本要求Vue CLI 需要 Node.js 8.9 或更高版本 (推荐 8.11.0+)。你可以使用 nvm 或 nvm-windows 在同一台电脑中管理多个 Node 版本。npm install -g @vue/cli# ORyarn global add @vue/cli  检查vue是否安装成功vue --version创建项目vue createvue ui这种是使用图形界面来创建项目，在命令行执行vue ui成功后浏览器会弹出一个http://localhost:8000的图形管理界面GUIVue GUI在命令行中执行vue ui 成功后，用浏览器打开Vue GUI,使用Vue GUI创建项目、管理项目、管理serve、编译项目build等。创建项目管理项目启动开发serve任务=&gt;serve=&gt;启动，等同于在命令行中执行下面的命令npx vue-cli-service serve编译项目任务=&gt;build=&gt;运行，等同于在命令行中执行下面的命令npx vue-cli-service build检查Webpack配置任务=&gt;inspect=&gt;运行Vue CLI配置在package.json文件的同目录下创建vue.config.jsmodule.exports = {	configureWebpack: {		entry: './src/main3223.js'//配置项目入口文件，默认的名称是main.js	}	pages: {		about: {			entry: 'src/pages/about/main.js',			template: 'public/about.html',			filename: 'about.html'		},		index: {			entry: 'src/pages/index/main.js',			template: 'public/index.html',			filename: 'index.html'		}	}}Vue CLI服务在一个 Vue CLI 项目中，@vue/cli-service 安装了一个名为 vue-cli-service 的命令。常用的vue-cliservice的命令有serve、build、inspect。package.json中配置vue-cli-service如下{  "scripts": {    "serve": "vue-cli-service serve",    "build": "vue-cli-service build",    "inspect": "vue-cli-service inspect"  }}使用npm可以执行npm run serve //开启servenpm run build //编译项目npm run inspect //审查webconfig配置文件Vue Router使用Vue GUI安装cli-plugin-router，会在原有的项目目录中生成以下目录和文件  /src/router/index.jsimport Vue from 'vue'import VueRouter from 'vue-router'import Home from '../views/Home.vue'Vue.use(VueRouter)const routes = [  {    path: '/',    name: 'home',    component: Home  },  {    path: '/about',    name: 'about',    // route level code-splitting    // this generates a separate chunk (about.[hash].js) for this route    // which is lazy-loaded when the route is visited.    component: () =&gt; import(/* webpackChunkName: "about" */ '../views/About.vue')  }]const router = new VueRouter({	mode: 'history',  routes})export default router      /src/views/About.view        /src/views/Home.view  Vue LoaderVue CLI插件Vue UI FrameworkVue UI框架  Element UI  Vuetify  Vue MaterialVue使用记录  .vue文件不能使用node.js的fs模块  import 和 export不能出现在代码块中，如果需要在代码块中引入文件，使用require  在App.vue组件中触发子组件中所定义的ref对应的v-on:click(“enterFull”)事件this.$refs.routerView.$children[5].$refs.enterFullScreen.click();  Chrome 浏览器在使用Element.requestFullscreen()方法时，如果不是手动触发点击事件的会报错failed to execute 'requestfullscreen' on 'element': api can only be initiated by a user gesture.参考资料  Vue.js 文档  Vue CLI 文档  vue.config.js配置文档  vue-router文档  vue-loader文档  webpack配置文档]]></content>
      <categories>
        
          <category> vue </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Vue.js 学习笔记]]></title>
      <url>/vue/2019/12/02/vue-js-learning/</url>
      <content type="text"><![CDATA[直接在HTML页面 &lt;script&gt;引入的方式vue.js 视频学习  学习视频网址安装直接用 &lt;script&gt; 引入  开发版本包含完整的警告和调试模式  生产版本删除了警告，33.30KB min+gzipNPM命令行工具 (CLI)Vue实例创建一个实例var vm = new Vue({  // 选项})数据与方法除了数据属性，Vue 实例还暴露了一些有用的实例属性与方法。它们都有前缀 $，以便与用户定义的属性区分开来。例如：var data = { a: 1 }var vm = new Vue({  el: '#example',  data: data})vm.$data === data // =&gt; truevm.$el === document.getElementById('example') // =&gt; true// $watch 是一个实例方法vm.$watch('a', function (newValue, oldValue) {  // 这个回调将在 `vm.a` 改变后调用})实例生命周期钩子每个 Vue 实例在被创建时都要经过一系列的初始化过程——例如，需要设置数据监听、编译模板、将实例挂载到 DOM 并在数据变化时更新 DOM 等。同时在这个过程中也会运行一些叫做生命周期钩子的函数，这给了用户在不同阶段添加自己的代码的机会。比如 created 钩子可以用来在一个实例被创建之后执行代码：new Vue({  data: {    a: 1  },  created: function () {    // `this` 指向 vm 实例    console.log('a is: ' + this.a)  }})// =&gt; "a is: 1"``Vue自定义实例下面的这个Vue实例，包含了  数据data  自定义的方法click1、click2,  实例生命周期的钩子beforeCreate、created、beforeMount等  Vue实例的方法$watchvar vm = new Vue({	el: '#app', 	data: {		msg:'hello Vue',		author:{name:'Zhaoqhu'},		rawHtml:'&lt;span style='color:red'&gt;;this is a html span &lt;/span&gt;',		color:'red',		number: 10,		ok: false,		strArr: 'vue',		isShowMe: false,		hrefOrg: 'https://cn.vuejs.org/v2/guide/syntax.html#%E5%8F%82%E6%95%B0',		clsClickTest: 'div-click-test',		isClsRed: true	},	methods:{		click1: function(){			console.log('click 1');		},		click2: function(){			console.log('click2');		}	},	beforeCreate: function(){		console.log('beforeCreate');	},	created: function(){		console.log('created');	},	beforeMount: function(){		console.log('beforemount');	},	mounted: function(){		console.log('mounted');	},	beforeUpdate: function(){		console.log('beforeupdate');	},	updated: function(){		console.log('updated');	}	});data.author.name='zhao Q.H.';	console.log(vm);	console.log(data);	vm.$watch('a',function(newVal,oldVal){		console.log(newVal,oldVal);	});setTimeout(function(){	vm.$data.msg = "hello vue223";},5000);console.log(vm.$data.strArr.split('').reverse().join(''));模版语法插值文本数据绑定最常见的形式就是使用“Mustache”语法 (双大括号) 的文本插值：&lt;div id="app"&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;原始HTML双大括号会将数据解释为普通文本，而非 HTML 代码。为了输出真正的 HTML，你需要使用 v-html 指令：&lt;div id="app"&gt;&lt;p id="rawHtmlA" v-html="rawHtml"&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;特性Mustache 语法不能作用在 HTML 特性上，HTML特性是指 id、class、href、title等遇到这种情况应该使用 v-bind 指令：&lt;div v-bind:class="color"&gt;hello red&lt;/div&gt;&lt;a v-bind:href="hrefOrg"&gt;跳转到官网&lt;/a&gt;&lt;div class="mar-top-30 font-30" v-bind:class="{fontRed:isClsRed}"&gt;使用Javascript表达式迄今为止，在我们的模板中，我们一直都只绑定简单的属性键值。但实际上，对于所有的数据绑定，Vue.js 都提供了完全的 JavaScript 表达式支持。&lt;p&gt;{{ number+1 }}&lt;/p&gt;&lt;p&gt;{{ ok ? 'YES' : 'NO' }}&lt;/p&gt;&lt;p&gt;{{ strArr.split('').reverse().join('') }}&lt;/p&gt;指令指令 (Directives) 是带有 v- 前缀的特殊特性。指令特性的值预期是单个 JavaScript 表达式 (v-for 是例外情况，稍后我们再讨论)。指令的职责是，当表达式的值改变时，将其产生的连带影响，响应式地作用于 DOM。回顾我们在介绍中看到的例子：参数一些指令能够接收一个“参数”，在指令名称之后以冒号表示。例如，v-bind 指令可以用于响应式地更新 HTML 特性：&lt;a v-bind:href="hrefOrg"&gt;跳转到官网&lt;/a&gt;&lt;div v-bind:class="clsClickTest"&gt;动态参数attributeName为动态参数，attributeValue为动态参数值eventName为动态参数,eventMethod为动态参数的静态方法&lt;a v-bind:[attributeName]="attributeValue"&gt;HTML动态属性和属性值&lt;/a&gt;&lt;a v-on:[eventName]="eventMethod"&gt;HTML动态事件和动态方法&lt;/a&gt;修饰符修饰符 (modifier) 是以半角句号 . 指明的特殊后缀，用于指出一个指令应该以特殊方式绑定。例如，.prevent 修饰符告诉 v-on 指令对于触发的事件调用 event.preventDefault()&lt;div @click="click1" v-bind:class="clsClickTest"&gt;	&lt;div v-on:click.stop="click2"&gt;	click me	&lt;/div&gt;&lt;/div&gt;缩写v- 前缀作为一种视觉提示，用来识别模板中 Vue 特定的特性。当你在使用 Vue.js 为现有标签添加动态行为 (dynamic behavior) 时，v- 前缀很有帮助，然而，对于一些频繁用到的指令来说，就会感到使用繁琐。同时，在构建由 Vue 管理所有模板的单页面应用程序 (SPA - single page application) 时，v- 前缀也变得没那么重要了。因此，Vue 为 v-bind 和 v-on 这两个最常用的指令，提供了特定简写：v-bind缩写&lt;!-- 完整语法 --&gt;&lt;a v-bind:href="url"&gt;...&lt;/a&gt;&lt;!-- 缩写 --&gt;&lt;a :href="url"&gt;...&lt;/a&gt;v-on缩写&lt;!-- 完整语法 --&gt;&lt;a v-on:click="doSomething"&gt;...&lt;/a&gt;&lt;!-- 缩写 --&gt;&lt;a @click="doSomething"&gt;...&lt;/a&gt;计算属性模板内的表达式非常便利，但是设计它们的初衷是用于简单运算的。在模板中放入太多的逻辑会让模板过重且难以维护。例如：&lt;div id="example"&gt;  {{ message.split('').reverse().join('') }}&lt;/div&gt;在这个地方，模板不再是简单的声明式逻辑。你必须看一段时间才能意识到，这里是想要显示变量 message 的翻转字符串。当你想要在模板中多次引用此处的翻转字符串时，就会更加难以处理。所以，对于任何复杂逻辑，你都应当使用计算属性。基础例子&lt;div id="example"&gt;  &lt;p&gt;Original message: "{{ message }}"&lt;/p&gt;  &lt;p&gt;Computed reversed message: "{{ reversedMessage }}"&lt;/p&gt;&lt;/div&gt;var vm = new Vue({  el: '#example',  data: {    message: 'Hello'  },  computed: {    // 计算属性的 getter    reversedMessage: function () {      // `this` 指向 vm 实例      return this.message.split('').reverse().join('')    }  }})计算属性缓存vs方法计算属性vs侦听属性计算属性的setter侦听器虽然计算属性在大多数情况下更合适，但有时也需要一个自定义的侦听器。这就是为什么 Vue 通过 watch 选项提供了一个更通用的方法，来响应数据的变化。当需要在数据变化时执行异步或开销较大的操作时，这个方式是最有用的。&lt;div id="watch-example"&gt;  &lt;p&gt;    Ask a yes/no question:    &lt;input v-model="question"&gt;  &lt;/p&gt;  &lt;p&gt;{{ answer }}&lt;/p&gt;&lt;/div&gt;&lt;!-- 因为 AJAX 库和通用工具的生态已经相当丰富，Vue 核心代码没有重复 --&gt;&lt;!-- 提供这些功能以保持精简。这也可以让你自由选择自己更熟悉的工具。 --&gt;&lt;script src="https://cdn.jsdelivr.net/npm/axios@0.12.0/dist/axios.min.js"&gt;&lt;/script&gt;&lt;script src="https://cdn.jsdelivr.net/npm/lodash@4.13.1/lodash.min.js"&gt;&lt;/script&gt;&lt;script&gt;var watchExampleVM = new Vue({  el: '#watch-example',  data: {    question: '',    answer: 'I cannot give you an answer until you ask a question!'  },  watch: {    // 如果 `question` 发生改变，这个函数就会运行    question: function (newQuestion, oldQuestion) {      this.answer = 'Waiting for you to stop typing...'      this.debouncedGetAnswer()    }  },  created: function () {    // `_.debounce` 是一个通过 Lodash 限制操作频率的函数。    // 在这个例子中，我们希望限制访问 yesno.wtf/api 的频率    // AJAX 请求直到用户输入完毕才会发出。想要了解更多关于    // `_.debounce` 函数 (及其近亲 `_.throttle`) 的知识，    // 请参考：https://lodash.com/docs#debounce    this.debouncedGetAnswer = _.debounce(this.getAnswer, 500)  },  methods: {    getAnswer: function () {      if (this.question.indexOf('?') === -1) {        this.answer = 'Questions usually contain a question mark. ;-)'        return      }      this.answer = 'Thinking...'      var vm = this      axios.get('https://yesno.wtf/api')        .then(function (response) {          vm.answer = _.capitalize(response.data.answer)        })        .catch(function (error) {          vm.answer = 'Error! Could not reach the API. ' + error        })    }  }})&lt;/script&gt;练习代码Javascript代码index.jsHTML代码参考资料  jekyll转义特殊字符]]></content>
      <categories>
        
          <category> vue </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[OAuth2 service microsoft]]></title>
      <url>/oauth2/2019/11/25/oAuth-2-service-microsoft/</url>
      <content type="text"><![CDATA[在网站中添加第三方microsoft帐号登录功能，方法和步骤访问authorization_endpoint。  authorization_endpoint的链接地址为https://login.microsoftonline.com/common/oauth2/v2.0/authorize?client_id=4ec1c7f2-9e38-4b8e-8073-5e6b68da2162&amp;response_type=code&amp;redirect_uri=http://localhost/oauth/callback_microsoft.php&amp;response_mode=query&amp;scope=openid%20profile%20email%20user.read&amp;state=12345&amp;prompt=consentauthorization_endpoint链接参数解释https://login.microsoftonline.com/common/oauth2/v2.0/authorize?client_id=4ec1c7f2-9e38-4b8e-8073-5e6b68da2162&amp; response_type=code&amp;redirect_uri=http://localhost/oauth/callback_microsoft.php&amp;response_mode=query&amp;scope=openid%20offline_access%20https%3A%2F%2Fgraph.microsoft.com%2Fuser.read&amp; //scope值需要rawurlencode()state=12345&amp; //state值需要rawurlencode();这个参数值可以自定义，并且会自动返回附加到回调地址上，prompt=consent//这个值，会使用户弹出一个登陆的界面访问authorization_endpoint的方式  使用JS访问authorization_endpointwindow.location.href = "https://login.microsoftonline.com/common/oauth2/v2.0/authorize?client_id=4ec1c7f2-9e38-4b8e-8073-5e6b68da2162&amp;response_type=code&amp;redirect_uri=http://localhost/oauth/callback_microsoft.php&amp;response_mode=query&amp;scope=openid%20profile%20email%20user.read&amp;state=12345&amp;prompt=consent";*使用PHP访问authorization_endpointheader("Location: https://login.microsoftonline.com/common/oauth2/v2.0/authorize?client_id=4ec1c7f2-9e38-4b8e-8073-5e6b68da2162&amp;response_type=code&amp;redirect_uri=http://localhost/oauth/callback_microsoft.php&amp;response_mode=query&amp;scope=openid%20profile%20email%20user.read&amp;state=12345&amp;prompt=consent");访问token_endpoint。$url_token = "https://login.microsoftonline.com/common/oauth2/v2.0/token";$data['client_id'] = '4ec1c7f2-9e38-4b8e-8073-5e6b68da2162';$scope = "openid profile email user.read";//$scope = "";$data['scope'] = $scope;$data['code'] = $_GET['code'];//这个值是访问访问authorization_endpoint的URL后自动返回的$data['redirect_uri'] = 'http://localhost/oauth/callback_microsoft.php';$data['grant_type'] = 'authorization_code';$data['client_secret'] = 'rlPw-4rgooGre:@8D?90p6py=LOPMG_0';$res = post_url($url_token,$data);$objToken = json_decode($res);访问userinfo_endpoint$url_userinfo = "https://graph.microsoft.com/v1.0/me";$header[] = "Authorization: ".$objToken-&gt;token_type." ".$objToken-&gt;access_token;//var_dump($url_userinfo,$header);die;$resUserInfo = get_url($url_userinfo,$header);var_dump(666,$resUserInfo);die;function get_url($url,$data){	$ch = curl_init();	curl_setopt($ch, CURLOPT_URL, $url);	curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);	curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE); 	curl_setopt($ch, CURLOPT_SSL_VERIFYHOST, FALSE); 	curl_setopt($ch, CURLOPT_CUSTOMREQUEST,"GET"); 	curl_setopt($ch, CURLOPT_HTTPHEADER, $data);	curl_setopt($ch, CURLOPT_PROXY, '127.0.0.1');	curl_setopt($ch, CURLOPT_PROXYPORT, '1080');	$output = curl_exec($ch);	if($output === false)	  {	      echo 'Curl error: ' . curl_error($ch);	  }	curl_close($ch);	return $output;}App registrations创建步骤1、访问https://portal.azure.com/#allservices2、Identity=&gt;App registrations=&gt;New registration3、registration主要参数有Application (client) ID，client secrect,创建方法选中已创建的registration=&gt;Certificates &amp; secrets=&gt; New client secrect4、开发过程中程序代码里client_id ，client_secret，redirect_uri，这三项的值，需要registration提供。参考资料  https://docs.microsoft.com/en-us/azure/active-directory/develop/v2-oauth2-auth-code-flow  https://docs.microsoft.com/en-us/graph/api/user-get?view=graph-rest-1.0&amp;tabs=http]]></content>
      <categories>
        
          <category> OAuth2 </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[OAuth2 service google]]></title>
      <url>/oauth2/2019/10/29/oAuth-2-service-google/</url>
      <content type="text"><![CDATA[在网站中添加第三方google帐号登录功能，方法和步骤访问authorization_endpoint。  authorization_endpoint的链接地址为https://accounts.google.com/o/oauth2/v2/auth?response_type=code&amp;scope=openid%20profile%20email&amp;redirect_uri=http://localhost/oauth/callback.php&amp;client_id=825260887949-tpka28ca3l4pacbjq83bdm1lnft58aga.apps.googleusercontent.com&amp;state=kwqrurwwlowpvnnprswlqxvwnsnwyymznrmupqsqvlpuumztvvdo&amp;access_type=offline&amp;prompt=consentauthorization_endpoint链接参数解释https://accounts.google.com/o/oauth2/v2/auth?response_type=code&amp;scope=openid%20profile%20email&amp; //scope值需要rawurlencode()redirect_uri=http://localhost/oauth/callback.php&amp;//redirect_uri值需要rawurlencode()client_id=825260887949-tpka28ca3l4pacbjq83bdm1lnft58aga.apps.googleusercontent.com&amp;//client_id值需要rawurlencode()state=kwqrurwwlowpvnnprswlqxvwnsnwyymznrmupqsqvlpuumztvvdo&amp;//state值需要rawurlencode();这个参数值可以自定义，并且会自动返回附加到回调地址上，access_type=offline&amp;prompt=consent//这个值，会使用户弹出一个登陆的界面访问authorization_endpoint的方式  使用JS访问window.location.href = https://accounts.google.com/o/oauth2/v2/auth?response_type=code&amp;scope=openid%20profile%20email&amp;redirect_uri=http://localhost/oauth/callback.php&amp;client_id=825260887949-tpka28ca3l4pacbjq83bdm1lnft58aga.apps.googleusercontent.com&amp;state=kwqrurwwlowpvnnprswlqxvwnsnwyymznrmupqsqvlpuumztvvdo&amp;access_type=offline&amp;prompt=consent  使用PHP访问header("Location: https://accounts.google.com/o/oauth2/v2/auth?response_type=code&amp;scope=openid%20profile%20email&amp;redirect_uri=http://localhost/oauth/callback.php&amp;client_id=825260887949-tpka28ca3l4pacbjq83bdm1lnft58aga.apps.googleusercontent.com&amp;state=kwqrurwwlowpvnnprswlqxvwnsnwyymznrmupqsqvlpuumztvvdo&amp;access_type=offline&amp;prompt=consent");访问token_endpoint。$data = array();$data['client_id'] = '825260887949-tpka28ca3l4pacbjq83bdm1lnft58aga.apps.googleusercontent.com';$data['client_secret'] = 'CeTlkOnFl3stgkTT4JgcxbWC';$data['grant_type'] = 'authorization_code';$data['redirect_uri'] = 'http://localhost/oauth/callback.php';$data['scope'] = '';$data['code'] = trim($_GET['code']); //这个值是访问访问authorization_endpoint的URL后自动返回的$url = 'https://www.googleapis.com/oauth2/v4/token';$res = post_url($url,$data);function post_url($url,$data){	$ch = curl_init();	curl_setopt($ch, CURLOPT_URL, $url);	curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);	curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE);	curl_setopt($ch, CURLOPT_SSL_VERIFYHOST,FALSE);	curl_setopt($ch, CURLOPT_POST, 1);	curl_setopt($ch, CURLOPT_POSTFIELDS, $data);	curl_setopt($ch, CURLOPT_PROXY, '127.0.0.1');	curl_setopt($ch, CURLOPT_PROXYPORT, '1080');	$output = curl_exec($ch);	  if($output === false)  {      echo 'Curl error: ' . curl_error($ch);  }  curl_close($ch);	return $output; }访问userinfo_endpoint$header[] = 'Authorization:'.$_SESSION['oauth2_google_token_type'].' '.$_SESSION['oauth2_google_access_token'];$request_url = "https://www.googleapis.com/oauth2/v2/userinfo";$res = get_url($request_url,$header);var_dump($res);die;function get_url($url,$data){	$ch = curl_init();	curl_setopt($ch, CURLOPT_URL, $url);	curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);	curl_setopt($ch, CURLOPT_SSL_VERIFYPEER, FALSE); 	curl_setopt($ch, CURLOPT_SSL_VERIFYHOST, FALSE); 	curl_setopt($ch, CURLOPT_CUSTOMREQUEST,"GET"); 	curl_setopt($ch, CURLOPT_HTTPHEADER, $data);	//curl_setopt($ch, CURLOPT_PROXY, '127.0.0.1');	//curl_setopt($ch, CURLOPT_PROXYPORT, '1080');	$output = curl_exec($ch);	if($output === false)	  {	      echo 'Curl error: ' . curl_error($ch);	  }	curl_close($ch);	return $output;}OAuth 2.0 client IDs创建步骤1、访问 Google API Console2、project=&gt;Credentials=&gt;OAuth client ID=&gt;Web application3、OAuth 2.0 client ID的主要参数有Client ID，Client secrect，Authorized redirect URIs4、开发过程中程序代码里client_id ，client_secret，redirect_uri，这三项的值，需要OAuth 2.0 client ID提供。google提供的在线使用API工具https://accounts.google.com/o/oauth2/v2/auth? scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.metadata.readonly&amp; access_type=offline&amp; include_granted_scopes=true&amp; state=state_parameter_passthrough_value&amp; redirect_uri=https://developers.google.com/oauthplayground&amp; response_type=code&amp; client_id=825260887949-tpka28ca3l4pacbjq83bdm1lnft58aga.apps.googleusercontent.com参数解释https://accounts.google.com/o/oauth2/v2/auth? scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.metadata.readonly&amp; access_type=offline&amp; include_granted_scopes=true&amp; state=state_parameter_passthrough_value&amp;//自定义我们网站里面需要使用的参数，会自动附加到回调地址上， redirect_uri=https://developers.google.com/oauthplayground&amp; //这个是google提供的在线API工具地址，这个回调地址需要添加到credentials response_type=code&amp; client_id=825260887949-tpka28ca3l4pacbjq83bdm1lnft58aga.apps.googleusercontent.com//这个是需要在google API console里创建credentials，然后在里面有client_id参考资料  Google OAuth 2 API 在线工具  https://developers.google.com/identity/protocols/OpenIDConnect]]></content>
      <categories>
        
          <category> OAuth2 </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Ubuntu 14.04 lts 升级到 16.04 lts]]></title>
      <url>/linux/2019/10/11/ubuntu14.04-lts-to-16.04-lts/</url>
      <content type="text"><![CDATA[故障描述升级到16.04后，只有命令行模式，没有网络，apt-get命令失效，故障原因解决方法重启电脑，同时一直按”Esc”键，进入GRUB界面apt-get错误apt: relocation error: version GLIBCXX_3.4.21 not defined in file libstdc++.so.6 with link time reference解决办法：需要网络可以正常访问外网，执行下面的命令$ wget http://security.ubuntu.com/ubuntu/pool/main/g/gcc-5/libstdc++6_5.4.0-6ubuntu1~16.04.10_amd64.debsudo dpkg -i libstdc++6_5.4.0-6ubuntu1~16.04.10_amd64.deb# I also found this helpful$ sudo apt-get -f install命令行模式切换到图形界面模式$ service lightdm start参考资料  命令行模式切换到图形界面模式  apt-get报错解决办法  修复ubuntu16.04，GRUB解决办法]]></content>
      <categories>
        
          <category> linux </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[chatroom]]></title>
      <url>/2019/10/09/chatroom/</url>
      <content type="text"><![CDATA[登录      参数  用户名：userName, 房间：roomId, 是否为主播：is_host        检查userName,roomId  如果userName,roomId的值为空则返回错误的提示信息。        检查某用户在某房间是否为主播  例如：userName的值为zhaoQH,roomId的值为北京666,检查zhaoQH在北京666的房间是否为主播        检查某用户是否已在房间  ]]></content>
      <categories>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Node.js学习笔记]]></title>
      <url>/node.js/2019/10/08/Nodejs-learning/</url>
      <content type="text"><![CDATA[安装  参考链接Node.js升级windows下升级windows下升级Nodejs比较简单，直接下载msi文件，安装覆盖原安装路径就可以了。由于众所周知的原因，国内访问Nodejs官网下载Nodejs安装文件时间非常DT的事，此处附上淘宝的国内镜像源，速度非常快。linux下升级  检查Node的当前版本$ node -v  清除npm cache$ sudo npm chache clean -f  node有一个模块叫n（这名字可够短的。。。），是专门用来管理node.js的版本的。$ npm install -g n  升级到最新稳定版本$ n stable  升级到指定版本$ n v4.4.7或者$ n 4.4.7npm升级  查看当前版本$ npm -v  升级至最新版本或者指定版本 @符号后面可以添加你想更新到的版本号。 latest代表是最新版本$ npm install npm@latest -g安装淘宝 NPM 镜像这是一个完整 npmjs.org 镜像，你可以用此代替官方版本(只读)，同步频率目前为 10分钟 一次以保证尽量与官方服务同步。$ npm install -g cnpm --registry=https://registry.npm.taobao.org使用cnpm安装模块从 registry.npm.taobao.org 安装所有模块. 当安装的时候发现安装的模块还没有同步过来, 淘宝 NPM 会自动在后台进行同步, 并且会让你从官方 NPM registry.npmjs.org 进行安装. 下次你再安装这个模块的时候, 就会直接从 淘宝 NPM 安装了.其它命令支持 npm 除了 publish 之外的所有命令, 如:$ cnpm install [name]补充常用npm命令$ npm -v          #显示版本，检查npm 是否正确安装。$ npm install express   #安装express模块$ npm install -g express  #全局安装express模块$ npm install --save express #会把express包安装到该目录下的node_modules目录中,会在package.json的dependencies属性下添加express,之后运行npm install 或者 npm install -production或者著名NODE_ENV变量值为production时，会自动安装express到node_module目录中.$ npm install --save-dev express #会把express包安装到该目录下的node_modules目录中,会在package.json的dependencies属性下添加express,之后运行npm install会自动安装express到node_module目录中但是执行npm install -production或者著名NODE_ENV变量值为production时，不会自动安装express到node_module目录中.$ npm install -D express # 等于npm install --save-dev express$ npm list         #列出已安装模块$ npm show express     #显示模块详情$ npm update        #升级当前目录下的项目的所有模块 $ npm update express    #升级当前目录下的项目的指定模块$ npm update -g express  #升级全局安装的express模块$ npm uninstall express  #删除指定的模块注：运行时需要用到的包使用npm install –save express，否则使用npm install –save-dev express。。参考资料  淘宝NPM镜像  https://github.com/tj/n  https://www.jb51.net/article/52409.htm  https://docs.npmjs.com/try-the-latest-stable-version-of-npm]]></content>
      <categories>
        
          <category> Node.js </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[browserify]]></title>
      <url>/node.js/2019/10/08/Browserify-watchify/</url>
      <content type="text"><![CDATA[介绍Browserify lets you require(‘modules’) in the browser by bundling up all of your dependencies.安装$ npm install -g browserify使用一  Here is a tutorial on how to use Browserify on the command line to bundle up a simple file called main.js along with all of its dependencies: main.jsvar unique = require('uniq');var data = [1, 2, 2, 3, 4, 5, 5, 5, 6];console.log(unique(data));  Install the uniq module with npm:npm install uniq  Now recursively bundle up all the required modules starting at main.js into a single file called bundle.js with the browserify command:browserify main.js -o bundle.js  Browserify parses the AST for require() calls to traverse the entire dependency graph of your project.Drop a single &lt;script&gt; tag into your html and you’re done!&lt;script src="bundle.js"&gt;&lt;/script&gt;使用二 browserify, watchify, socket.io-client, jquery、  安装browserify , socket.io-client, watchify$ npm i browserify --save-dev$ npm install --save socket.io-client$ npm i watchify --save-dev$npm i --save jquery  package.json{  "name": "app",  "version": "1.0.0",  "description": "",  "main": "main.js",  "scripts": {    "build": "browserify main.js -o ../server/public/bundle.js",    "watch": "watchify main.js -o bundle.js"  },  "author": "",  "license": "ISC",  "dependencies": {    "socket.io-client": "^2.3.0"  }}  main.js文件使用require引入js模块  执行命令，编译和监控文件$ npm run build$ npm run watch参考资料http://browserify.org/]]></content>
      <categories>
        
          <category> Node.js </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[jekyll学习笔记]]></title>
      <url>/jekyll/2019/09/29/jekyll-learning/</url>
      <content type="text"><![CDATA[jekyll安装 使用~ $ gem install jekyll~ $ jekyll new myblog~ $ cd myblog~/myblog $ jekyll serve //启动方式一，如果有错，尝试启动方式二~/myblog $ bundle exec jekyll serve //启动方式二# =&gt; Now browse to http://localhost:4000jekyll代码块转义特殊字符如何显示呢{{  }} 具体如下： {% raw %}{{ msg }} {% endraw %}  参考资料  jekyll如何转义特殊字符]]></content>
      <categories>
        
          <category> jekyll </category>
        
      </categories>
      <tags>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[mediasoup]]></title>
      <url>/mediasoup/2019/09/27/mediasoup/</url>
      <content type="text"><![CDATA[learning mediasoup A WebRTC SFU for Node.jsFULL MESHMCU: MULTIPOINT CONTROL UNITSFU: SELECTIVE FORWARDING UNITmediasoup-clientmediasoup-client安装npm install mediasoup-client@3 --save浏览器端使用Node.js模块mediasoup-client      JavaScript ES6 plus CommonJS        browserify 、webpack、gulp  ubunto 安装mediasoupv3  新建mediasoupv3-zhaoqhu目录，分别创建app,server目录$ mkdir mediasoupv3-zhaoqhu$ mkdir server$ mkdir app$ cd server$ npm init$ sudo npm install mediasoup@3 --save --unsafe-perm=true --allow-root  检查gcc 版本 如果gcc版本小于 4.9，需要升级gcc到4.9以上，ubunto 14.04 lts 好像最高的gcc 版本是 4.8.5，升级 ubunto 到 16.04 lts首先添加ppa到库：$ sudo add-apt-repository ppa:ubuntu-toolchain-r/test$ sudo apt-get update$ sudo apt-get upgrade$ sudo apt-get $ sudo apt-get install gcc-4.8 g++-4.8$ sudo apt-get install gcc-4.9 g++-4.9$ sudo apt-get install gcc-5 g++-5mediasoup server.js分析const fs = require('fs');   //文件系统   	fs.readFileSync(path[,options]) //方法用于同步读取文件，返回一个字符串。	cert : fs.readFileSync(config.https.tls.cert),	key  : fs.readFileSync(config.https.tls.key)--------------------------------------const https = require('https');--------------------------------------const url = require('url'); //模块用于生成和解析URL。该模块使用前，必须加载。	url.parse(urlString[, parseQueryString[, slashesDenoteHost]]) //The url.parse() method takes a URL string, parses it, and returns a URL object.	const u = url.parse(info.request.url, true);const protoo = require('protoo-server');const mediasoup = require('mediasoup');----------------------------------------const express = require('express'); //Express 是一个简洁而灵活的 node.js Web应用框架, 提供了一系列强大特性帮助你创建各种 Web 应用，和丰富的 HTTP 工具。const expressApp = express();expressApp.use()和app.METHOD()(METHOD包括get(),put(),post(),delete())都是express应用层中间件，处理用户浏览器端发起到服务端的请求，但是一般情况下expressApp.use()都写在app.METHOD()前面，然后在use()中间件函数里写一些公共的代码，然后next()到METHOD()中间件函数中。expressApp.use(bodyParser.json()); //expressApp.param([name],callback); //执行Express路由(expressApp.get(),expressApp.post(),expressApp.put(),expressApp.delete()),会触发expressApp.param()这个方法，expressApp.param('roomId', (req, res, next, roomId) =&gt;{	// The room must exist for all API requests.	if (!rooms.has(roomId))	{		const error = new Error(`room with id "${roomId}" not found`);		error.status = 404;		throw error;	}	req.room = rooms.get(roomId);	next();});----------------------------------------const bodyParser = require('body-parser');body-parser是express框架常用的一个中间件，作用是对post请求的请求体进行解析。结合express().use()和express().METHOD()的使用方法，expressApp.use(bodyParser.json()); expressApp.post('/rooms/:roomId/broadcasters', async (req, res, next) =&gt;{})-----------------------------------------const AwaitQueue = require('awaitqueue');这个Node.js组件是Mediasoup的作者编写的，-----------------------------------------const Logger = require('./lib/Logger');const Room = require('./lib/Room');const interactiveServer = require('./lib/interactiveServer');const interactiveClient = require('./lib/interactiveClient');  multiparty引入的moudleconst config = require('./config/config');const fs = require('fs');const http = require('http');-------------------------------const spdy = require('spdy');//配置http访问方式-------------------------------const express = require('express');--------------------------------const compression = require('compression');app.user(compression()) //通过 Gzip 压缩，有助于显著降低响应主体的大小，从而提高 Web 应用程序的速度。可使用压缩中间件进行 Express 应用程序中的 gzip 压缩。例如--------------------------------const mediasoup = require('mediasoup');const AwaitQueue = require('awaitqueue');const Logger = require('./lib/Logger');const Room = require('./lib/Room');const utils = require('./util');----------------------------------------const base64 = require('base-64');// 加密解密参数state : base64.encode(JSON.stringify({	roomId : req.query.roomId,	peerId : req.query.peerId,	code   : utils.random(10)}))const state = JSON.parse(base64.decode(req.query.state));----------------------------------------------const passport = require('passport');-------------------------------------const { Issuer, Strategy } = require('openid-client');const session = require('express-session');mediasoup-client知识点  new mediasoupClient.Device(); //实例化mediasoupClent  await this._mediasoupDevice.load()  this._mediasoupDevice.createSendTransport()  this._mediasoupDevice.createRecvTransport()  this._mediasoupDevice.canProduce();mediasoup知识点  const mediasoupWorker = mediasoup.createWorker()  const mediasoupRouter = mediasoupWorker.createRouter({ mediaCodecs });  this._mediasoupRouter.canConsume()  this._mediasoupRouter.rtpCapabilities;  mediasoupWorker.close();  const audioLevelObserver = await mediasoupRouter.createAudioLevelObserver();  const transport = await this._mediasoupRouter.createWebRtcTransport();  transport.setMaxIncomingBitrate(maxIncomingBitrate); }  transport.connect({ dtlsParameters });  transport.restartIce();  await transport.produce({ kind, rtpParameters, appData })  await transport.getStats();  consumer = await transport.consume();multiparty 工作流程      app-&gt;src-&gt;index.js    logger.debug(‘DOM ready’);        app-&gt;src-&gt;RoomClient.js  export default class RoomClient{	static init(data){}	constructor({ roomId, peerId, device, useSimulcast, produce, consume, forceTcp }){logger.debug('constructor() [roomId: "%s", peerId: "%s", device: "%s", useSimulcast: "%s", produce: "%s", consume: "%s", forceTcp: "%s"]',roomId, peerId, device.flag, useSimulcast, produce, consume, forceTcp);}	------------------------------------------	close(){logger.debug('close()');}	------------------------------------------	_startKeyListener(){}	_startDevicesListener(){}	login(){}	logout(){}	closeLoginWindow(){}	_soundNotification(){logger.error('_soundAlert.play() | failed: %o', error);}	notify(text){}	timeoutCallback(callback){}	sendRequest(method, data){// 发送命令到服务端socketreturn new Promise((resolve, reject) =&gt;		{			if (!this._signalingSocket)			{				reject('No socket connection.');			}			else			{				this._signalingSocket.emit(					'request',					{ method, data },					this.timeoutCallback((err, response) =&gt;					{						if (err)						{							reject(err);						}						else						{							resolve(response);						}					})				);			}		});		}	async changeDisplayName(displayName){logger.debug('changeDisplayName() [displayName:"%s"]', displayName);}	async changeProfilePicture(picture){logger.debug('changeProfilePicture() [picture: "%s"]', picture);}	async sendChatMessage(chatMessage){logger.debug('sendChatMessage() [chatMessage:"%s"]', chatMessage);}	saveFile(file){}	handleDownload(magnetUri){}	_handleTorrent(torrent){}	async shareFiles(files){}	async _sendFile(magnetUri){logger.debug('sendFile() [magnetUri: %o]', magnetUri);}	async getServerHistory(){logger.debug('getServerHistory()');}	------------------------------------------	async muteMic(){logger.debug('muteMic()');}	async unmuteMic(){logger.debug('unmuteMic()');}	------------------------------------------	async updateSpotlights(spotlights){logger.debug('updateSpotlights()');}	async changeAudioDevice(deviceId){logger.debug('changeAudioDevice() [deviceId: %s]', deviceId);}	async changeVideoResolution(resolution){logger.debug('changeVideoResolution() [resolution: %s]', resolution);}	async changeWebcam(deviceId){logger.debug('changeWebcam() [deviceId: %s]', deviceId);}	setSelectedPeer(peerId){logger.debug('setSelectedPeer() [peerId:"%s"]', peerId);}	async modifyPeerConsumer(peerId, type, mute){logger.debug('modifyPeerConsumer() [peerId:"%s", type:"%s"]',peerId,type);}	async _pauseConsumer(consumer){logger.debug('_pauseConsumer() [consumer: %o]', consumer);}	async _resumeConsumer(consumer){logger.debug('_resumeConsumer() [consumer: %o]', consumer);}	async sendRaiseHandState(state){logger.debug('sendRaiseHandState: ', state);}	async join({ joinVideo }){		this._signalingSocket = io(this._signalingUrl);		logger.debug('signaling Peer "connect" event');		this._signalingSocket.on('connect',()=&gt;{logger.debug('signaling Peer "connect" event');});		this._signalingSocket.on('disconnect',()=&gt;{logger.warn('signaling Peer "disconnect" event');});		this._signalingSocket.on('close',()=&gt;{logger.warn('signaling Peer "close" event');});		this._signalingSocket.on('request',async (request, cb)=&gt;{logger.debug(				'socket "request" event [method:%s, data:%o]',				request.method, request.data);				});		this._signalingSocket.on('notification', async (notification)=&gt;{			switch (notification.method)			{				case 'roomReady':{}				case 'roomLocked':{}				case 'lockRoom':{}				case 'unlockRoom':{}				case 'activeSpeaker':{}				case 'changeDisplayName':{}				case 'changeProfilePicture':{}				case 'auth':{}				case 'chatMessage':{}				case 'sendFile':{}				case 'producerScore':{}				case 'newPeer':{}				case 'peerClosed':{}				case 'consumerClosed':{}				case 'consumerPaused':{}				case 'consumerResumed':{}				case 'consumerLayersChanged':{}				case 'consumerScore':{}			}			});		this._signalingSocket.on('connect',()=&gt;{});		this._signalingSocket.on('connect',()=&gt;{});		this._signalingSocket.on('connect',()=&gt;{});		this._signalingSocket.on('connect',()=&gt;{});		this._signalingSocket.on('connect',()=&gt;{});		this._signalingSocket.on('connect',()=&gt;{});	}	async _joinRoom({ joinVideo }){		logger.debug('_joinRoom()');		this._mediasoupDevice = new mediasoupClient.Device(); //实例化mediasoupClent		const routerRtpCapabilities = await this.sendRequest('getRouterRtpCapabilities') //socket.io发送mediasoup命令		await this._mediasoupDevice.load({ routerRtpCapabilities }); //mediasoup-client根据socket.io发送命令返回来的数据load()		if(this._produce){			//socket.io发送Producer命令			const transportInfo = await this.sendRequest( 'createWebRtcTransport',{forceTcp  : this._forceTcp,producing : true,consuming : false});			//定义并接收socket.io返回来的值			const {id,iceParameters,iceCandidates,dtlsParameters} = transportInfo;			//mediasoupClient创建发送通道			this._sendTransport = this._mediasoupDevice.createSendTransport({id,iceParameters,iceCandidates,dtlsParameters});			this._sendTransport.on('connect',(){})			this._sendTransport.on('produce',(){})		}		if(this._consumer){			//socket.io发送consumer创建webRTC通道			const transportInfo = await this.sendRequest('createWebRtcTransport',{forceTcp  : this._forceTcp,producing : false,consuming : true});			const {id,iceParameters,iceCandidates,dtlsParameters} = transportInfo;			//mediasoupClient创建接受通道			this._recvTransport = this._mediasoupDevice.createRecvTransport(			{				id,				iceParameters,				iceCandidates,				dtlsParameters			});		}		//socket.io发送join命令		const { peers } = await this.sendRequest(		'join',{displayName: displayName,picture: picture,device: this._device,			rtpCapabilities : this._consume				? this._mediasoupDevice.rtpCapabilities				: undefined		});			}	------------------------------------------	async lockRoom(){		logger.debug('lockRoom()');		//socket.io发送lockRoom命令		await this.sendRequest('lockRoom');	}	async unlockRoom(){		logger.debug('unlockRoom()');		//socket.io发送unlockRoom命令		await this.sendRequest('unlockRoom');	}	------------------------------------------	async enableMic(){		logger.debug(				'enableMic() | new selected audio device [device:%o]',device);		logger.debug('enableMic() | calling getUserMedia()');		this._micProducer = await this._sendTransport.produce(		{			track,			codecOptions :			{				opusStereo : 1,				opusDtx    : 1			},			appData : 			{ source: 'mic' }		});	}	async disableMic(){		logger.debug('disableMic()');		await this.sendRequest(				'closeProducer', { producerId: this._micProducer.id });	}	------------------------------------------	async enableScreenSharing(){}	async disableScreenSharing(){}	------------------------------------------	async enableWebcam(){		if (!this._mediasoupDevice.canProduce('video')		this._sendTransport.producetrack,					appData : 					{						source : 'webcam'					}				})	}	async disableWebcam(){		logger.debug('disableWebcam()');		this._webcamProducer = await this.sendRequest(				'closeProducer', { producerId: this._webcamProducer.id });	}	------------------------------------------	async _updateAudioDevices(){logger.debug('_updateAudioDevices()');}	async _updateWebcams(){logger.debug('_updateWebcams()');}	async _getAudioDeviceId(){logger.debug('_getAudioDeviceId()');}	async _getWebcamDeviceId(){logger.debug('_getWebcamDeviceId()');}}浏览器端browser和服务端server通信服务端地址：const url = wss://${hostname}:${port}/?peerId=${peerId}&amp;roomId=${roomId};服务端用到的roomId,和peerId是通过浏览器端定义并传递过去的browser通过初始化socket.io-client初始化socket.io-client默认向服务端socket.io服务发送connection命令，服务端socket.io监听到connection命令后，根据browser端socket.io-client传递过来的roomId参数，执行获取或者创建房间,async join(){this._signalingSocket = io(this._signalingUrl)}=============&gt;async function runWebSocketServer(){	const io = require('socket.io')(httpsServer);	io.on('connection', (socket) =&gt;	{		const { roomId, peerId } = socket.handshake.query;		if (!roomId || !peerId)		{			logger.warn('connection request without roomId and/or peerId');			socket.disconnect(true);			return;		}		logger.info(			'connection request [roomId:"%s", peerId:"%s"]', roomId, peerId);		queue.push(async () =&gt;		{			const room = await getOrCreateRoom({ roomId }); //创建房间			room.handleConnection({ peerId, socket }); //创建peer		})		.catch((error) =&gt;		{			logger.error('room creation or room joining failed:%o', error);			socket.disconnect(true);			return;		});	});}创建房间方法getOrCreateRoom({roomId})房间数量受到mediasoupWorkers的限制，mediasoupWorkers的数量是config配置文件里根据cpu的性能限制，在开启服务 node server.js运行时，就执行了runMediasoupWorkers()方法根据配置文件把mediasoupWorkers初始化成数组了，该数组包含了所有可用的mediasoupworker了，创建房间用到的方法是Room.js里面的create()方法，在执行create方法里面又通过传递参数mediasoupworker,创建了mediasoupRouter,创建房间成功后执行room.handleConnection方法,创建房间成功后执行this._notification(socket, ‘roomReady’)，发送命令roomReady给socket.io-client;async function getOrCreateRoom({ roomId }){	let room = rooms.get(roomId);	// If the Room does not exist create a new one.	if (!room)	{		logger.info('creating a new Room [roomId:%s]', roomId);		const mediasoupWorker = getMediasoupWorker();		room = await Room.create({ mediasoupWorker, roomId });		rooms.set(roomId, room);		room.on('close', () =&gt; rooms.delete(roomId));	}	return room;}async function runMediasoupWorkers(){	const { numWorkers } = config.mediasoup;	logger.info('running %d mediasoup Workers...', numWorkers);	for (let i = 0; i &lt; numWorkers; ++i)	{		const worker = await mediasoup.createWorker(			{				logLevel   : config.mediasoup.worker.logLevel,				logTags    : config.mediasoup.worker.logTags,				rtcMinPort : config.mediasoup.worker.rtcMinPort,				rtcMaxPort : config.mediasoup.worker.rtcMaxPort			});		worker.on('died', () =&gt;		{			logger.error(				'mediasoup Worker died, exiting  in 2 seconds... [pid:%d]', worker.pid);			setTimeout(() =&gt; process.exit(1), 2000);		});		mediasoupWorkers.push(worker);	}}/** * Get next mediasoup Worker. */function getMediasoupWorker(){	const worker = mediasoupWorkers[nextMediasoupWorkerIdx];	if (++nextMediasoupWorkerIdx === mediasoupWorkers.length)		nextMediasoupWorkerIdx = 0;	return worker;}服务端Room.js创建房间成功后,执行room.handleConnection，创建Peerpeer创建成功后执行peer._handlePeer(),创建一个peer对象，_handlePeer({ peer, consume })	{		logger.debug('_handlePeer() [peer:"%s"]', peer.id);		peer.data = {};		// Not joined after a custom protoo 'join' request is later received.		peer.data.consume = consume;		peer.data.joined = false;		peer.data.displayName = undefined;		peer.data.device = undefined;		peer.data.rtpCapabilities = undefined;		peer.data.raiseHandState = false;		// Have mediasoup related maps ready even before the Peer joins since we		// allow creating Transports before joining.		peer.data.transports = new Map();		peer.data.producers = new Map();		peer.data.consumers = new Map();		peer.socket.on('request', (request, cb) =&gt;		{			logger.debug(				'Peer "request" event [method:%s, peerId:%s]',				request.method, peer.id);			this._handleSocketRequest(peer, request, cb)				.catch((error) =&gt;				{					logger.error('request failed:%o', error);					cb(error);				});		});		peer.socket.on('disconnect', () =&gt;		{			if (this._closed)				return;			logger.debug('Peer "close" event [peerId:%s]', peer.id);			// If the Peer was joined, notify all Peers.			if (peer.data.joined)			{				this._notification(peer.socket, 'peerClosed', { peerId: peer.id }, true);			}			const index = this._lastN.indexOf(peer.id);			if (index &gt; -1) // We have this peer in the list, remove			{				this._lastN.splice(index, 1);			}			// Iterate and close all mediasoup Transport associated to this Peer, so all			// its Producers and Consumers will also be closed.			for (const transport of peer.data.transports.values())			{				transport.close();			}			this._peers.delete(peer.id);			// If this is the latest Peer in the room, close the room after a while.			if (this._peers.size === 0)			{				setTimeout(() =&gt;				{					if (this._closed)						return;					if (this._peers.size === 0)					{						logger.info(							'last Peer in the room left, closing the room [roomId:%s]',							this._roomId);						this.close();					}				}, 10000);			}		});	}工作流程  浏览器端通过join方法使用socket.io-client，发送connection命令，  服务端通过监听connection命令，创建mediasoupWorker,  然后在创建room和mediasoupRouter,  然后在创建Peer  然后通过socket.io发送给浏览器端roomReady命令ecmscript6 es6知识点  new Map();const rooms = new Map();rooms.has(roomId)rooms.get(roomId)rooms.set(roomId, room);      export default class RoomClient{} //在创建JavaScript模块时，export 语句用于从模块中导出函数、对象或原始值，以便其他程序可以通过 import 语句使用它们。        static function(){} //静态方法不能用 new 实例调用        … Spread syntax展开语法return (…args) =&gt;  ]]></content>
      <categories>
        
          <category> mediasoup </category>
        
      </categories>
      <tags>
        
          <tag> mediasoup </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[使用video.js播放dash、m3u8、mp4视频文件。]]></title>
      <url>/videojs/2019/09/26/videojs-play-dash-m3u8-mp4/</url>
      <content type="text"><![CDATA[使用video.js播放dash、m3u8、mp4视频文件。video.js播放Mp4&lt;head&gt;  &lt;link href="https://vjs.zencdn.net/7.6.5/video-js.css" rel="stylesheet"&gt;  &lt;!-- If you'd like to support IE8 (for Video.js versions prior to v7) --&gt;  &lt;script src="https://vjs.zencdn.net/ie8/1.1.2/videojs-ie8.min.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;  &lt;video id='my-video' class='video-js' controls preload='auto' width='640' height='264'  poster='MY_VIDEO_POSTER.jpg' data-setup='{}'&gt;    &lt;source src='MY_VIDEO.mp4' type='video/mp4'&gt;    &lt;source src='MY_VIDEO.webm' type='video/webm'&gt;    &lt;p class='vjs-no-js'&gt;      To view this video please enable JavaScript, and consider upgrading to a web browser that      &lt;a href='https://videojs.com/html5-video-support/' target='_blank'&gt;supports HTML5 video&lt;/a&gt;    &lt;/p&gt;  &lt;/video&gt;  &lt;script src='https://vjs.zencdn.net/7.6.5/video.js'&gt;&lt;/script&gt;&lt;/body&gt;video.js播放MPEG-DASH&lt;video id=example-video width=600 height=300 class="video-js vjs-default-skin" controls&gt; &lt;/video&gt;&lt;script src="video.js"&gt;&lt;/script&gt;&lt;script src="dash.all.js"&gt;&lt;/script&gt;&lt;script src="videojs-dash.min.js"&gt;&lt;/script&gt;&lt;script&gt;  var player = videojs('example-video');  player.src({ src: 'https://example.com/dash.mpd', type: 'application/dash+xml'});  player.play();&lt;/script&gt;video.js播放M3U8&lt;video id=example-video width=960 height=540 class="video-js vjs-default-skin" controls&gt;  &lt;source     src="https://example.com/index.m3u8"     type="application/x-mpegURL"&gt;&lt;/video&gt;&lt;script src="video.js"&gt;&lt;/script&gt;&lt;script src="videojs.hls.min.js"&gt;&lt;/script&gt;&lt;script&gt;var player = videojs('example-video');player.play();&lt;/script&gt;下载资源链接  video.js  dash.all.js  videojs-dash.min.js  videojs-hls.min.js参考资料  Video.js Setup  VideoJS MPEG-DASH博客=&gt;https://videojs.github.io/videojs-contrib-dash/  VideoJS m3u8博客=&gt;https://videojs.github.io/videojs-contrib-hls/]]></content>
      <categories>
        
          <category> videojs </category>
        
      </categories>
      <tags>
        
          <tag> videojs </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[mysql 储存 emoji表情符]]></title>
      <url>/mysql/2019/09/25/emoji-utf8mb4/</url>
      <content type="text"><![CDATA[mysql使用utf8mb4储存emoji表情符，mysql odbc driver 不兼容utf8mb4Unicode简介Unicode（中文：万国码、国际码、统一码、单一码）是计算机科学领域里的一项业界标准。它对世界上大部分的文字系统进行了整理、编码，使得计算机可以用更为简单的方式来呈现和处理文字。位于美国加州的Unicode组织允许任何愿意支付会费的公司和个人加入，其成员包含了主要的计算机软硬件厂商，例如Adobe系统、苹果公司、惠普、IBM、微软、施乐等。Unicode 自版本 2.0 开始保持了向后兼容，即新的版本仅仅增加字符，原有字符不会被删除或更名。目前版本是Unicode 12.1,统一码联盟在 1991 年首次发布了 The Unicode Standard。Unicode 的开发结合了国际标准化组织所制定的 ISO/IEC 10646，即通用字符集。基本多文种平面的字符的编码为 U+hhhh，其中每个 h 代表一个十六进制数字emoji表情符简介emoji（英语：emoji，日语：絵文字／えもじ emoji），最早由栗田穰崇（Shigetaka Kurita）创作,是一种形象化的符号，包括人的面部表情、肢体动作、各种动物、各种植物、各种食物、各种体育活动、各种交通工具、各种交通标志、各种国旗等形象化符号的总称。2010年10月发布的Unicode 6.0版首次收录emoji编码。emoji储存到mysql  utf8_unicode_ci和utf8mb4_unicode_ci的异同这两种collations所对应的字符都是UTF-8编码的一个子集。utf8_unicode_ci最多能找到3个字节的Unicode编码，而utf8mb4_unicode_ci则能找到4个字节的编码。由于调整后的UTF-8编码格式规定最多使用4字节（原来是6字节）编码，所以utf8mb4系列可以说是覆盖了整个Unicode编码。由于utf8_unicode_ci最多能找到3个字节的编码，意味着它只支持BMP中的字符，对于SMP与SIP以及其他头一字节不为0x00、需要4字节编码的planes来说，utf8_unicode_ci这种collation是无法支持。当使用4字节的字符（如emoji与B区以后的统一汉字）对使用此种collation的字段进行增删查改时，数据库会报一个非法字符的异常。而utf8mb4则没有此问题。由此也看出，utf8mb4_unicode_ci是utf8_unicode_ci的超集。emoji储存到数据库需要4个字节bytes,需要字段的字符集设置成为utf8mb4，  设置字段字符集为utf8mb4，字符集校对utf8mb4_unicode_cimysql配置和修改字符集  如果是已经存在的项目，现在存在的数据表和未来创建的数据表每个字段都支持4个字节(emoji)的存储，那么需要修改修改配置文件、已存在的数据库字符集、数据表字符集、字段字符集修改mysql配置文件[client]no-beepdefault-character-set = utf8mb4# pipe# socket=0.0port=7349[mysql]no-beep#default-character-set=utf8default-character-set = utf8mb4[mysqld]#character-set-server=utf8character-set-server = utf8mb4collation-server = utf8mb4_unicode_ci修改数据库的字符集ALTER SCHEMA `lti`  DEFAULT CHARACTER SET utf8mb4  DEFAULT COLLATE utf8mb4_unicode_ci ;修改表的字符集ALTER TABLE `lti`.`item` CHARACTER SET = utf8mb4 , COLLATE = utf8mb4_unicode_ci ;修改字段的字符集ALTER TABLE `lti`.`item` CHANGE COLUMN `item_text` `item_text` TEXT CHARACTER SET 'utf8mb4' COLLATE 'utf8mb4_unicode_ci' NULL DEFAULT NULL ;  如果只需要某个字段支持emoji4字节存储，可以直接修改这个字段的字符集就可以了，不用修改配置文件等。ALTER TABLE `lti`.`item` CHANGE COLUMN `item_text` `item_text` TEXT CHARACTER SET 'utf8mb4' COLLATE 'utf8mb4_unicode_ci' NULL DEFAULT NULL ;mysql odbc driver 不兼容utf8mb4如果服务端脚本语言Asp使用的mysql odbc driver操作数据库，涉及到utf8mb4的字段会出现错误，试过了很多版本的mysql-connector-odbc-8.0.x-winx64.msi都不可以，最后安装使用mariadb-connector-odbc-3.0.9-win64,解决了odbcd dirver不兼容utf8mb4的问题其他服务端脚本语言PHP没有使用mysql odbc driver没有发现问题。参考资料  mariadb odbc driver 3.0.9  mysql odbc driver 历史版本  Unicode 维基百科  emoji 维基百科  emoji unicode UTF-8 =&gt; https://apps.timwhitlock.info/emoji/tables/unicode]]></content>
      <categories>
        
          <category> mysql </category>
        
      </categories>
      <tags>
        
          <tag> mysql </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
    <entry>
      <title><![CDATA[Git学习笔记]]></title>
      <url>/git/2019/09/23/Git-learing/</url>
      <content type="text"><![CDATA[Git配置，获取Git仓库，远程仓库管理，合并Commit知识点  repository //仓库  git本地仓库  git远程仓库(github或搭建服务端git仓库)  staged files //Changes to be committed 缓存区文件  unstaged files //Changes not staged for commit 已跟踪文件，并且修改后为加入缓存区文件  Untracked Files // 未跟踪的文件安装Git  用浏览器打开Git官方网址https://git-scm.com/downloads,  选择适配自己电脑系统的Git(Mac、Windows、Linux/Unix)配置用户信息全局配置$ git config --global user.name "Zhao QH"$ git config --global user.email "Zhaoqhu@gmail.com"局部配置$ cd ./git_programs/special_program$ git config user.name "ZhaoQingHu"$ git config user.email "izhaoqinghu@gmail.com"创建本地Git仓库$ cd ./git_programs/first_git$ echo "# zhaoqhu.github.io" &gt;&gt; README.md$ git init$ git add README.md$ git commit -m "first commit"git Commit提交git commit -m "提交信息"#将本次提交追加到上一次提交，不会产生新的commitIDgit commit -m "新的提交信息" --amend使用SSH连接到GitHub本地计算机SSH设置参考连接：https://help.github.com/cn/articles/connecting-to-github-with-ssh一台计算机配置一个Github账户SSH密钥  执行下面的shell命令列出已存在的SSH密钥    $ ls -al ~/.ssh        如果.ssh目录下不为空可能包含以下文件，说明本地计算机已经存在SSH密钥,否则本地计算机尚未生成SSH密钥： id_dsa.pub，id_ecdsa.pub，id_ed25519.pub，id_rsa.pub    生成新的SSH密钥     $ ssh-keygen        如果~/.ssh目录下没有文件，生成新的SSH密钥，按回车键几次后生成了id_rsa.pub，id_dsa.pub    复制id_rsa.pub这个文件里的内容添加到gihub账户，可以使用下面的命令也可以直接用编辑器或者VIM打开*.pub文件进行Copy    $ clip &lt; ~/.ssh/id_rsa.pub        添加到Github账户 Github账户=&gt;settings=&gt;SSH and GPG Keys=&gt;New SSH Key  使用下方的命令，测试账号配置是否成功    $ ssh -T git@github.com        一台计算机配置多个Github账户SSH密钥    本地计算机生成SSH密钥    $ ssh-keygen  -t rsa    -f ~/.ssh/github_zhaoqhu   -C "zhaoqhu@gmail.com"        ssh-keygen -t 密钥类型  -f 密钥文件路径及名称  -C 备注信息    检查~/.ssh目录下是否有config文件，添加一下内容    #Github account oneHost git.github.comHostName github.comIdentityFile ~/.ssh/id_rsa#Github account twoHost zhaoqhu.github.comHostName github.comIdentityFile ~/.ssh/github_zhaoqhu        复制~/.ssh目录下的github_zhaoqhu.pub文件里的内容=》githu帐号=&gt;settings=&gt;SSH and GPG Keys=&gt;New SSH Key  测试帐号配置是否成功$ ssh -T git@zhaoqhu.github.com管理远程仓库查看远程仓库$ git remote -v添加远程仓库$ git remote add orgin git@zhaoqhu.github.com:zhaoqhu/zhaoqhu.github.io.gitgit remote add 名称 URL重命名远程仓库$ git remote rename origin destination将远程仓库名称从 ‘origin’ 更改为 ‘destination’删除远程$ git remote rm destinationgit remote rm 远程名称修改远程仓库URL  方法一git remote -v  #查看远端地址git remote #查看远端仓库名git remote set-url origin https://gitee.com/xx/xx.git (新地址)  方法二git remote rm origin #删除远程的仓库git remote add origin  https://gitee.com/xx/xx.git(新地址) #重新添加远程仓库注：git remote rm 不会从服务器中删除远程仓库。 它只是从本地仓库中删除远程及其引用。  方法三直接修改.git目录下的config配置文件[core]	repositoryformatversion = 0	filemode = false	bare = false	logallrefupdates = true	symlinks = false	ignorecase = true[remote "origin"]	#将这里=号后的值换成需要的远程仓库值	url = git@github.com:zhaoqhu/zhaoqhu.github.io.git	fetch = +refs/heads/*:refs/remotes/origin/*[branch "master"]	remote = origin	merge = refs/heads/mastergit设置忽略目录和文件网上查询有三种方法可以实现忽略目录和文件，本方法使用在.git版本库的同级目录下添加.gitignore文件，只能忽略那些原来没有被track的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的里面的解决已经在版本库中的目录或者文件不能被忽略#比如_site目录已经在版本库中，执行下面的命令将_site目录变成未跟踪状态Untrackedgit rm --cached _sitegit commit -m "update _site gitignore".gitignore文件内容如下#忽略_site文件夹及文件夹下文件_site/*_theme_packages/*Thumbs.db.DS_Store!.gitkeep.rbenv-version.rvmrc/vendor合并Commit  git log -n查看Commit提交历史记录$ git log -n 6commit 8365c47d028c2e1a33f6c12b89c71d94757e18ae (HEAD -&gt; master, origin/master)Author: Zhao QH &lt;zhaoqhu@gmail.com&gt;Date:   Mon Sep 23 17:34:43 2019 +0800    fix:合并3commit 1485a27e8fb6031186422273190da2f25de65c5dAuthor: Zhao QH &lt;zhaoqhu@gmail.com&gt;Date:   Mon Sep 23 15:53:35 2019 +0800    modify _config searchcommit b26a1f5d0c649823a50b85e122f8eab07e2479adAuthor: Zhao QH &lt;zhaoqhu@gmail.com&gt;Date:   Mon Sep 23 15:19:10 2019 +0800    modify _config.ymlcommit 30a89ae0bcc3600adcf3ed042c9df2d58a1f2d89Author: Zhao QH &lt;zhaoqhu@gmail.com&gt;Date:   Mon Sep 23 15:06:52 2019 +0800    modify _config.ymlcommit cd574a978e947cf1ef92c8d68bfdfb39fe954798Author: Zhao QH &lt;zhaoqhu@gmail.com&gt;Date:   Mon Sep 23 11:32:30 2019 +0800    jekyll-theme-next template initcommit 823d9a66db7482ebdf52e20b4f67b9786e9e28f8Author: Zhao QH &lt;zhaoqhu@gmail.com&gt;Date:   Wed Sep 18 14:45:29 2019 +0800    first commit  git rebase -i 后面的参数可以是HEAD~5,或者是Commit的ID号(example:823d9a66db7482ebdf52e20b4f67b9786e9e28f8)$ git rebase -i HEAD~5   按下回车后，我们会进入到这么一个界面，最上面显示的几行是提交历史记录，按提交的时间倒序，最上面的是最早Commit的，pick cd574a9 jekyll-theme-next template initpick 30a89ae modify _config.ymlpick b26a1f5 modify _config.ymlpick 1485a27 modify _config searchpick 8365c47 fix:合并3# Rebase 823d9a6..8365c47 onto 823d9a6 (5 commands)## Commands:# p, pick = use commit# r, reword = use commit, but edit the commit message# e, edit = use commit, but stop for amending# s, squash = use commit, but meld into previous commit# f, fixup = like "squash", but discard this commit's log message# x, exec = run command (the rest of the line) using shell# d, drop = remove commit## These lines can be re-ordered; they are executed from top to bottom.## If you remove a line here THAT COMMIT WILL BE LOST.## However, if you remove everything, the rebase will be aborted.## Note that empty commits are commented out  把需要合并的Commit前面的pick改成squash或者s如下,pick cd574a9 jekyll-theme-next template initpick 30a89ae modify _config.ymlpick b26a1f5 modify _config.ymlpick 1485a27 modify _config searchs 8365c47 fix:合并3# Rebase 823d9a6..8365c47 onto 823d9a6 (5 commands)## Commands:# p, pick = use commit# r, reword = use commit, but edit the commit message# e, edit = use commit, but stop for amending# s, squash = use commit, but meld into previous commit# f, fixup = like "squash", but discard this commit's log message# x, exec = run command (the rest of the line) using shell# d, drop = remove commit## These lines can be re-ordered; they are executed from top to bottom.## If you remove a line here THAT COMMIT WILL BE LOST.## However, if you remove everything, the rebase will be aborted.## Note that empty commits are commented out  然后按ESC键=&gt;Shift+:键=&gt;wq,保存退出,如果一切顺利会弹出一个画面,如果文件有冲突需要解决后，然后执行git rebase –continue$git rebase --continue错误解决后，可以调到下面的界面# This is a combination of 2 commits.# This is the 1st commit message:modify _config search# This is the commit message #2:fix:合并3# Please enter the commit message for your changes. Lines starting# with '#' will be ignored, and an empty message aborts the commit.## Date:      Mon Sep 23 15:53:35 2019 +0800## interactive rebase in progress; onto 823d9a6# Last commands done (5 commands done):#    pick 1485a27 modify _config search#    squash 8365c47 fix:合并3# No commands remaining.# You are currently rebasing branch 'master' on '823d9a6'.## Changes to be committed:#       modified:   Gemfile.lock#       modified:   _config.yml#       new file:   "_posts/2019-09-23-Git\345\255\246\344\271\240\347\254\224\350\256\260.md"## Untracked files:#       .jekyll-metadata  合并Commit的信息fix:合并4# Please enter the commit message for your changes. Lines starting# with '#' will be ignored, and an empty message aborts the commit.## Date:      Mon Sep 23 15:53:35 2019 +0800## interactive rebase in progress; onto 823d9a6# Last commands done (5 commands done):#    pick 1485a27 modify _config search#    squash 8365c47 fix:合并3# No commands remaining.# You are currently rebasing branch 'master' on '823d9a6'.## Changes to be committed:#       modified:   Gemfile.lock#       modified:   _config.yml#       new file:   "_posts/2019-09-23-Git\345\255\246\344\271\240\347\254\224\350\256\260.md"## Untracked files:#       .jekyll-metadata  合并完成注：git rebase 操作应该只用于本地尚未提交到远程仓库的 commit，一旦 push 到远端仓库，则不再允许修改 commit，否则可能会给其他开发者带来很多麻烦。尤其是多人协作时，千万要注意。。github page  How to Build a Static Jekyll Site with Github Pages    参考资料    使用 Git =&gt;https://help.github.com/cn/categories/using-git  git Book =&gt;https://git-scm.com/book/zh/v2  使用 SSH 连接到 GitHub =&gt;https://help.github.com/cn/articles/connecting-to-github-with-ssh  A3.1 附录 C: Git 命令 - 设置与配置 =&gt;https://git-scm.com/book/zh/v2/%E9%99%84%E5%BD%95-C%3A-Git-%E5%91%BD%E4%BB%A4-%E8%AE%BE%E7%BD%AE%E4%B8%8E%E9%85%8D%E7%BD%AE]]></content>
      <categories>
        
          <category> Git </category>
        
      </categories>
      <tags>
        
          <tag> Git </tag>
        
      </tags>
      <tags></tags>
    </entry>
  
</search>
